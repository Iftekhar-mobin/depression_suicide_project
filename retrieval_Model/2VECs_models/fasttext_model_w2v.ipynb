{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# fn = fasttext.load_model('/home/ifte/resource/wikiextractor/wikidata/eng/fasttext.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "fn = fasttext.load_model('/home/iftekhar/AI-system/retrieval_Model/2VECs_models/wikidata/model.100.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07667947, -0.06120841, -0.09435041,  0.04501336,  0.03741806,\n",
       "       -0.04196567,  0.1633161 ,  0.0724503 ,  0.05553149,  0.11562091,\n",
       "       -0.03246967, -0.07164875,  0.11796255,  0.11751541, -0.12792848,\n",
       "       -0.04665038,  0.08198808,  0.18017825, -0.11247236,  0.1294755 ,\n",
       "        0.01496095,  0.08012428,  0.01069938, -0.02893267,  0.07160071,\n",
       "       -0.04108928,  0.01765375,  0.11632745,  0.1028231 , -0.04332729,\n",
       "        0.0649609 , -0.04521976, -0.0361555 ,  0.01685878,  0.02819698,\n",
       "       -0.03056016,  0.1020413 , -0.02637937,  0.07652242,  0.01573678,\n",
       "        0.0067738 ,  0.10595183, -0.04485988, -0.14754939, -0.10057092,\n",
       "        0.06850751,  0.13249566,  0.04426245, -0.03898132,  0.09526465,\n",
       "       -0.09887021,  0.04775145, -0.09119613,  0.10619222, -0.03923333,\n",
       "       -0.00573721, -0.01276552,  0.15215597, -0.04408273,  0.08662661,\n",
       "       -0.07654064,  0.10465898, -0.02120063, -0.10118195, -0.04013037,\n",
       "       -0.09019438, -0.04808171, -0.00299828,  0.05167866, -0.04747479,\n",
       "       -0.11976089, -0.05141119, -0.07004181, -0.00784197, -0.01965909,\n",
       "       -0.00669385, -0.12364963, -0.00907745, -0.0068546 , -0.20150276,\n",
       "        0.0490902 , -0.06396109,  0.04129826,  0.13321358, -0.17508669,\n",
       "        0.04323725,  0.1830003 ,  0.06781515,  0.22114313, -0.07882386,\n",
       "       -0.18653806,  0.13454062, -0.09377886, -0.00189605,  0.13297644,\n",
       "        0.00823625, -0.03408744, -0.02321979, -0.01338053, -0.10780201],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.get_sentence_vector('hi there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ifte/resource/1810/data/processed_texts.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = []\n",
    "i = 0\n",
    "for items in lines:\n",
    "    print('-', i)\n",
    "    collector.append(fn.get_sentence_vector(items.strip('\\n')))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "def dump_to_file(file_path, data):\n",
    "    with open(file_path, 'wb') as output_file:\n",
    "        pickle.dump(data, output_file)\n",
    "\n",
    "def load_from_file(file_path):\n",
    "    with open(file_path, \"rb\") as input_file:\n",
    "        data = pickle.load(input_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_to_file('/home/ifte/AI-system/retrieval_Model/2VECs_models/vectors.pkl', collector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector=load_from_file('/home/ifte/AI-system/retrieval_Model/2VECs_models/vectors.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'カード 情報 保存 ついて'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fn.get_sentence_vector(query)\n",
    "rank = []\n",
    "ids = 0\n",
    "for vec in collector:\n",
    "    rank.append((ids, cos_sim(X, vec)))\n",
    "    ids += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(762, 0.88000786),\n",
       " (87, 0.8384698),\n",
       " (1063, 0.8362517),\n",
       " (1208, 0.83240265),\n",
       " (1216, 0.8323103)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(rank, key=lambda l:l[1], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8252137303352356, 'rehires'),\n",
       " (0.8048502206802368, 'receptionist'),\n",
       " (0.7971470355987549, 'quitting'),\n",
       " (0.79229336977005, 'intern'),\n",
       " (0.7847083806991577, 'getting'),\n",
       " (0.7835538387298584, 'betterpaying'),\n",
       " (0.7829933166503906, 'jobs'),\n",
       " (0.7793596386909485, 'quit'),\n",
       " (0.7776588797569275, 'quits'),\n",
       " (0.7694813013076782, 'salesperson')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.get_nearest_neighbors('job', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " out = [(0.8998978137969971, '深める'),\n",
    " (0.8949190974235535, '相応しい'),\n",
    " (0.8888064026832581, 'cats'),\n",
    " (0.8732790946960449, 'monkey'),\n",
    " (0.8698340654373169, 'ducklings'),\n",
    " (0.8672646880149841, 'kitten'),\n",
    " (0.8606615662574768, 'rabbit'),\n",
    " (0.8568143844604492, 'raccoon'),\n",
    " (0.8537366390228271, '非難'),\n",
    " (0.8528804183006287, 'duckling')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "def load_from_file(file_path):\n",
    "    with open(file_path, \"rb\") as input_file:\n",
    "        data = pickle.load(input_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_from_file('/home/ifte/resource/docomo_dic/data/unique_synonyms.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['非難']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for s, w in out if w=='非難']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sorted([(s, w) for s, w in out if w in d.keys()], reverse=True)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'深める'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(result) > 1:\n",
    "    sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "# model = load_facebook_model('/home/iftekhar/myworkplace/AI-system/2VECs_models/word2vec/fasttext_model.bin')\n",
    "# model = load_facebook_model('/home/ifte/resource/wikiextractor/wikidata/eng/fasttext.model.bin')\n",
    "# model = load_facebook_model('/home/iftekhar/AI-system/retrieval_Model/2VECs_models/wikidata/cc.ja.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_facebook_model('/home/iftekhar/AI-system/retrieval_Model/2VECs_models/wikidata/context_50_v_2000000.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sent = [['lord', 'of', 'the', 'rings'], ['lord', 'of', 'the', 'flies']]\n",
    "\n",
    "model.build_vocab(new_sent, update=True)\n",
    "\n",
    "model.train(sentences=new_sent, total_examples=len(new_sent), epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "query = 'CE 後継 ある Windows Embedded プラットフォーム 電話機 なにで'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model.wv.get_vector(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = model.wv.get_vector('インストール べき に関する 情報 送り 送る べき どうでしたか')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7527098"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import load_facebook_model \n",
    "import compress_fasttext\n",
    "big_model = load_facebook_model('/home/iftekhar/myworkplace/AI-system/2VECs_models/word2vec/fasttext_model.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model = compress_fasttext.svd_ft(big_model)\n",
    "small_model.save('/home/iftekhar/myworkplace/AI-system/2VECs_models/word2vec/fasttext_model_compressed.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now instead of 16Gb of RAM, our model will take only 10Gb.\n",
    "from gensim.models import FastText\n",
    "# Original fasttext embeddings from https://fasttext.cc/\n",
    "ft = FastText.load_fasttext_format('/home/iftekhar/myworkplace/AI-system/2VECs_models/word2vec/fasttext_model.model')\n",
    "# we are not saving trainables here\n",
    "#big_model.wv.save('/home/iftekhar/myworkplace/AI-system/2VECs_models/word2vec/fasttext_model.model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = LineSentence('/home/ifte/resource/wikiextractor/wikidata/eng/wikidata_all_processed_cleaned.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(size=100, window=10, max_vocab_size=1000000, workers=4) \n",
    "\n",
    "# build the vocabulary\n",
    "model.build_vocab(sentences=sentences)\n",
    "\n",
    "# train the model\n",
    "model.train(sentences=sentences, total_examples=len(sentences))\n",
    "model.save('/home/ifte/resource/wikiextractor/wikidata/eng/wikidata/en_fasttext_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(vector_size=4, window=3, min_count=1)  # instantiate\n",
    "model.build_vocab(sentences=common_texts)\n",
    "model.train(sentences=common_texts, total_examples=len(common_texts), epochs=10)  # train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VEC FILE LOADING\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('/home/ifte/resource/wikiextractor/wikidata/eng/fasttext.model.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('winter', 0.8838561773300171),\n",
       " ('spring', 0.847408652305603),\n",
       " ('autumn', 0.8426227569580078),\n",
       " ('midOctober', 0.808631956577301),\n",
       " ('summerearly', 0.7972444295883179),\n",
       " ('midSeptember', 0.7934184670448303),\n",
       " ('winterearly', 0.7845533490180969),\n",
       " ('midNovember', 0.7805715799331665),\n",
       " ('summering', 0.7778684496879578),\n",
       " ('NovemberMarch', 0.7748517394065857)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"summer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49490836"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"summer\", \"hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "m = gensim.models.KeyedVectors.load_word2vec_format('wiki-news-300d-1M.vec')\n",
    "m.save_word2vec_format('wiki-news-300d-1M.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.models.fasttext.load_facebook_model(path, encoding='utf-8')\n",
    "\n",
    "Load the input-hidden weight matrix from Facebook’s native fasttext .bin output file.\n",
    "load_facebook_model() loads the full model, not just word embeddings, and enables you to continue model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import load_facebook_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = load_facebook_vectors('/home/ifte/resource/wikiextractor/wikidata/eng/fasttext.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ifte/environments/experiment_env/lib/python3.6/site-packages/gensim/models/keyedvectors.py:2389: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('pet', 0.8998980522155762),\n",
       " ('dog', 0.8949192762374878),\n",
       " ('cats', 0.8888064026832581),\n",
       " ('monkey', 0.8732790350914001),\n",
       " ('ducklings', 0.8698340058326721),\n",
       " ('kitten', 0.8672646284103394),\n",
       " ('rabbit', 0.8606615662574768),\n",
       " ('raccoon', 0.8568143844604492),\n",
       " ('fox', 0.8537366390228271),\n",
       " ('duckling', 0.8528804779052734)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.most_similar('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.models.fasttext.load_facebook_vectors(path, encoding='utf-8')\n",
    "\n",
    "Load word embeddings from a model saved in Facebook’s native fasttext .bin format.\n",
    "load_facebook_vectors() loads the word embeddings only. Its faster, but does not enable you to continue training.\n",
    "\n",
    "from gensim.test.utils import datapath\n",
    ">>>\n",
    "\n",
    "cap_path = datapath(\"crime-and-punishment.bin\")\n",
    "\n",
    "fb_model = load_facebook_model(cap_path)\n",
    ">>>\n",
    "\n",
    "'landlord' in fb_model.wv.key_to_index  # Word is out of vocabulary\n",
    "False\n",
    "\n",
    "oov_term = fb_model.wv['landlord']\n",
    ">>>\n",
    "\n",
    "'landlady' in fb_model.wv.key_to_index  # Word is in the vocabulary\n",
    "True\n",
    "\n",
    "iv_term = fb_model.wv['landlady']\n",
    ">>>\n",
    "\n",
    "new_sent = [['lord', 'of', 'the', 'rings'], ['lord', 'of', 'the', 'flies']]\n",
    "\n",
    "fb_model.build_vocab(new_sent, update=True)\n",
    "\n",
    "fb_model.train(sentences=new_sent, total_examples=len(new_sent), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load just a subset of the full-word vectors from the plain-text .vec file. For example, to load just the 1st 500K vectors:\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "KeyedVectors.load_word2vec_format('cc.de.300.vec', limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.vec is a text file containing the word vectors, one per line. model.bin is a binary file containing the parameters of the model along with the dictionary and all hyper parameters.\n",
    "\n",
    "In other words, .vec file format is the same as .txt file format, and you could use it in other applications (for example, to exchange data between your FastText model and your Word2Vec model since .vec file is similar to .txt file generated by Word2Vec). And the .bin file could be used if you want to continue training the vectors or to restart the optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
