{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ifte/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# if nltk data is not present\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the data txt file on disk.\n",
    "data_path = \"../Dataset/English_for_Today.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here mecab tokenizer needed to tokenize the input data \n",
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    #lines = f.read().split('\\n')\n",
    "    lines = f.read()\n",
    "\n",
    "#print(lines)   \n",
    "\n",
    "# Here mecab tokenizer needed to tokenize the input data \n",
    "wordsList = nltk.word_tokenize(lines)\n",
    "#print(wordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('Col%d(C-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('Col%d(C)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('Col%d(C+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56002,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npwordsList = np.asarray(wordsList) \n",
    "npwordsList.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = LabelEncoder()\n",
    "e = encoded.fit_transform(npwordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56002,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5600, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also use padding technique here to make the length of number of token even number\n",
    "# shaping according to desired pattern samples, Timestep, Predicted output length \n",
    "d = e[:-2].reshape(npwordsList[:len(npwordsList)-2].shape[0]//10,10)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1(C-3)</th>\n",
       "      <th>Col2(C-3)</th>\n",
       "      <th>Col3(C-3)</th>\n",
       "      <th>Col4(C-3)</th>\n",
       "      <th>Col5(C-3)</th>\n",
       "      <th>Col6(C-3)</th>\n",
       "      <th>Col7(C-3)</th>\n",
       "      <th>Col8(C-3)</th>\n",
       "      <th>Col9(C-3)</th>\n",
       "      <th>Col10(C-3)</th>\n",
       "      <th>...</th>\n",
       "      <th>Col1(C+4)</th>\n",
       "      <th>Col2(C+4)</th>\n",
       "      <th>Col3(C+4)</th>\n",
       "      <th>Col4(C+4)</th>\n",
       "      <th>Col5(C+4)</th>\n",
       "      <th>Col6(C+4)</th>\n",
       "      <th>Col7(C+4)</th>\n",
       "      <th>Col8(C+4)</th>\n",
       "      <th>Col9(C+4)</th>\n",
       "      <th>Col10(C+4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>2747.0</td>\n",
       "      <td>6587.0</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>884.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>2446.0</td>\n",
       "      <td>2205.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2182.0</td>\n",
       "      <td>2039.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>1703.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>1577.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>4013.0</td>\n",
       "      <td>6587.0</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>6076.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>...</td>\n",
       "      <td>873.0</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>863.0</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>1808.0</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>878.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>532.0</td>\n",
       "      <td>2157.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>1833.0</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2180.0</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1928.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>1931.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>1699.0</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>885.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>1747.0</td>\n",
       "      <td>1523.0</td>\n",
       "      <td>1831.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>1391.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>3969.0</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>7105.0</td>\n",
       "      <td>343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1794.0</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>1517.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>1704.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2747.0</td>\n",
       "      <td>6587.0</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>5194.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>2747.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>1682.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5591</td>\n",
       "      <td>6603.0</td>\n",
       "      <td>6599.0</td>\n",
       "      <td>6993.0</td>\n",
       "      <td>6595.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>1748.0</td>\n",
       "      <td>2324.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2989.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>2156.0</td>\n",
       "      <td>6763.0</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5216.0</td>\n",
       "      <td>2216.0</td>\n",
       "      <td>1387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5592</td>\n",
       "      <td>6587.0</td>\n",
       "      <td>3995.0</td>\n",
       "      <td>5338.0</td>\n",
       "      <td>5194.0</td>\n",
       "      <td>6587.0</td>\n",
       "      <td>6381.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>6593.0</td>\n",
       "      <td>7095.0</td>\n",
       "      <td>2377.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2359.0</td>\n",
       "      <td>6587.0</td>\n",
       "      <td>5263.0</td>\n",
       "      <td>2216.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>6598.0</td>\n",
       "      <td>7063.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>5414.0</td>\n",
       "      <td>7113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5593</td>\n",
       "      <td>6646.0</td>\n",
       "      <td>6598.0</td>\n",
       "      <td>5671.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>2205.0</td>\n",
       "      <td>2862.0</td>\n",
       "      <td>7044.0</td>\n",
       "      <td>6763.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4229.0</td>\n",
       "      <td>4750.0</td>\n",
       "      <td>4422.0</td>\n",
       "      <td>6587.0</td>\n",
       "      <td>2217.0</td>\n",
       "      <td>5670.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2171.0</td>\n",
       "      <td>2764.0</td>\n",
       "      <td>2336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5594</td>\n",
       "      <td>2989.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3969.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2359.0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>3969.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6847.0</td>\n",
       "      <td>7119.0</td>\n",
       "      <td>5288.0</td>\n",
       "      <td>7063.0</td>\n",
       "      <td>2359.0</td>\n",
       "      <td>5414.0</td>\n",
       "      <td>6646.0</td>\n",
       "      <td>3325.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5595</td>\n",
       "      <td>601.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>3896.0</td>\n",
       "      <td>7063.0</td>\n",
       "      <td>2359.0</td>\n",
       "      <td>5414.0</td>\n",
       "      <td>4422.0</td>\n",
       "      <td>6587.0</td>\n",
       "      <td>6583.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>4607.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>7355.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>4323.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5593 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Col1(C-3)  Col2(C-3)  Col3(C-3)  Col4(C-3)  Col5(C-3)  Col6(C-3)  \\\n",
       "3        1684.0     2747.0     6587.0     1531.0      884.0       56.0   \n",
       "4        1983.0     4013.0     6587.0     2222.0     6076.0      346.0   \n",
       "5         532.0     2157.0     1730.0     1833.0     1437.0       84.0   \n",
       "6        1941.0     1788.0     1411.0     1437.0      564.0     1747.0   \n",
       "7        1794.0     1191.0     1517.0      792.0       56.0     1951.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "5591     6603.0     6599.0     6993.0     6595.0      553.0      683.0   \n",
       "5592     6587.0     3995.0     5338.0     5194.0     6587.0     6381.0   \n",
       "5593     6646.0     6598.0     5671.0       84.0       91.0     1413.0   \n",
       "5594     2989.0       84.0      854.0       91.0     3969.0     1387.0   \n",
       "5595      601.0       84.0     1991.0     3896.0     7063.0     2359.0   \n",
       "\n",
       "      Col7(C-3)  Col8(C-3)  Col9(C-3)  Col10(C-3)  ...  Col1(C+4)  Col2(C+4)  \\\n",
       "3        1983.0      749.0     2446.0      2205.0  ...     2182.0     2039.0   \n",
       "4         975.0     1039.0     1955.0       847.0  ...      873.0     1475.0   \n",
       "5        2180.0     1151.0     1133.0      1788.0  ...     1928.0      691.0   \n",
       "6        1523.0     1831.0      986.0      1391.0  ...       56.0     1983.0   \n",
       "7         689.0       71.0      892.0      1704.0  ...     2747.0     6587.0   \n",
       "...         ...        ...        ...         ...  ...        ...        ...   \n",
       "5591      665.0      549.0     1748.0      2324.0  ...     2989.0       84.0   \n",
       "5592       71.0     6593.0     7095.0      2377.0  ...     2359.0     6587.0   \n",
       "5593     2205.0     2862.0     7044.0      6763.0  ...     4229.0     4750.0   \n",
       "5594     2359.0      854.0      325.0      3969.0  ...     6847.0     7119.0   \n",
       "5595     5414.0     4422.0     6587.0      6583.0  ...     1387.0     4607.0   \n",
       "\n",
       "      Col3(C+4)  Col4(C+4)  Col5(C+4)  Col6(C+4)  Col7(C+4)  Col8(C+4)  \\\n",
       "3         985.0     1065.0     1703.0      549.0     1577.0      345.0   \n",
       "4        1204.0     1297.0      865.0      863.0     1344.0     1808.0   \n",
       "5        1931.0      565.0     1224.0     1699.0     1306.0      928.0   \n",
       "6         749.0     1078.0     1091.0      946.0     3969.0     2222.0   \n",
       "7        1134.0     5194.0      708.0       84.0     1691.0     2747.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "5591      325.0     2156.0     6763.0     3330.0       72.0     5216.0   \n",
       "5592     5263.0     2216.0      602.0     6598.0     7063.0       87.0   \n",
       "5593     4422.0     6587.0     2217.0     5670.0       84.0     2171.0   \n",
       "5594     5288.0     7063.0     2359.0     5414.0     6646.0     3325.0   \n",
       "5595       71.0     2790.0     7355.0        5.0        5.0      601.0   \n",
       "\n",
       "      Col9(C+4)  Col10(C+4)  \n",
       "3        1982.0       931.0  \n",
       "4        1386.0       878.0  \n",
       "5        1531.0       885.0  \n",
       "6        7105.0       343.0  \n",
       "7         549.0      1682.0  \n",
       "...         ...         ...  \n",
       "5591     2216.0      1387.0  \n",
       "5592     5414.0      7113.0  \n",
       "5593     2764.0      2336.0  \n",
       "5594     6590.0        84.0  \n",
       "5595     4323.0        71.0  \n",
       "\n",
       "[5593 rows x 80 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hours = 3\n",
    "n_features = 5\n",
    "n_ahead = 10\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(d, n_hours, n_features)\n",
    "reframed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "npwordsList = np.asarray(wordsList) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "#Index(['Col1(C-3)', 'Col2(C-3)', 'Col3(C-3)', 'Col4(C-3)', 'Col5(C-3)',\n",
    "#       'Col6(C-3)', 'Col7(C-3)', 'Col8(C-3)', 'Col9(C-3)', 'Col10(C-3)',\n",
    "#       'Col1(C-2)', 'Col2(C-2)', 'Col3(C-2)', 'Col4(C-2)', 'Col5(C-2)',\n",
    "#       'Col6(C-2)', 'Col7(C-2)', 'Col8(C-2)', 'Col9(C-2)', 'Col10(C-2)',\n",
    "#       'Col1(C-1)', 'Col2(C-1)', 'Col3(C-1)', 'Col4(C-1)', 'Col5(C-1)',\n",
    "#       'Col6(C-1)', 'Col7(C-1)', 'Col8(C-1)', 'Col9(C-1)', 'Col10(C-1)',\n",
    "#       'Col1(C)', 'Col2(C)', 'Col3(C)', 'Col4(C)', 'Col5(C)', 'Col6(C)',\n",
    "#       'Col7(C)', 'Col8(C)', 'Col9(C)', 'Col10(C)', 'Col1(C+1)', 'Col2(C+1)',\n",
    "#       'Col3(C+1)', 'Col4(C+1)', 'Col5(C+1)', 'Col6(C+1)', 'Col7(C+1)',\n",
    "#       'Col8(C+1)', 'Col9(C+1)', 'Col10(C+1)', 'Col1(C+2)', 'Col2(C+2)',\n",
    "#       'Col3(C+2)', 'Col4(C+2)', 'Col5(C+2)', 'Col6(C+2)', 'Col7(C+2)',\n",
    "#       'Col8(C+2)', 'Col9(C+2)', 'Col10(C+2)', 'Col1(C+3)', 'Col2(C+3)',\n",
    "#       'Col3(C+3)', 'Col4(C+3)', 'Col5(C+3)', 'Col6(C+3)', 'Col7(C+3)',\n",
    "#       'Col8(C+3)', 'Col9(C+3)', 'Col10(C+3)', 'Col1(C+4)', 'Col2(C+4)',\n",
    "#       'Col3(C+4)', 'Col4(C+4)', 'Col5(C+4)', 'Col6(C+4)', 'Col7(C+4)',\n",
    "#       'Col8(C+4)', 'Col9(C+4)', 'Col10(C+4)'],\n",
    "#      dtype='object')\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "st = (n_hours+1)*n_ahead + 1  \n",
    "\n",
    "# drop columns we don't want to predict\n",
    "deletedcol =    list(reframed.columns)[st           :  st+n_ahead-1] +                 list(reframed.columns)[st+n_ahead   :  st+n_ahead*2-1] +                 list(reframed.columns)[st+n_ahead*2 :  st+n_ahead*3-1] +                 list(reframed.columns)[st+n_ahead*3 : ] \n",
    "#print(\"deleted column\",deletedcol)\n",
    "\n",
    "reframed.drop(deletedcol, axis=1, inplace=True)\n",
    "#print(reframed.head())\n",
    "\n",
    "#reframed.to_csv(r'outNum.csv')\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "\n",
    "# decoding to see the formation\n",
    "\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "train_size = int(len(values) * 0.8)\n",
    "test_size = len(values) - train_size\n",
    "train, test = values[0:train_size,:], values[train_size:,:]\n",
    "\n",
    "input_col = (n_hours+1)*n_ahead\n",
    "\n",
    "## split into input and outputs\n",
    "train_X, train_y = train[:, :input_col], train[:, -4:]\n",
    "test_X, test_y = test[:, :input_col], test[:, -4:]\n",
    "#print(train_X, train_X.shape, train_y, train_y.shape)\n",
    "\n",
    "\n",
    "# In[53]:\n",
    "\n",
    "\n",
    "print(train_X.shape, test_y.shape)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "\n",
    "# In[57]:\n",
    "\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(160, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(4))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=100, batch_size=40, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "\n",
    "\n",
    "# In[62]:\n",
    "\n",
    "\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "yhat\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "\n",
    "yhat = yhat.reshape(-1)\n",
    "print(yhat.shape)\n",
    "encoded.inverse_transform()\n",
    "\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "\n",
    "\n",
    "#test_X = test_X.reshape((test_X.shape[0], n_hours*n_features))\n",
    "# invert scaling for forecast\n",
    "#inv_yhat = concatenate((yhat, test_X[:, -7:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "#inv_y = concatenate((test_y, test_X[:, -7:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
