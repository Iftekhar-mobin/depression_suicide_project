{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56550863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from string import punctuation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a16ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "faq =pd.read_csv('../input/mental-health-faq-for-chatbot/Mental_Health_FAQ.csv')\n",
    "faq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f90da",
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_quest = faq[['Question_ID', 'Questions']]\n",
    "faq_answ = faq[['Question_ID', 'Answers']]\n",
    "\n",
    "def to_lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def expand_contraction(text, contraction_dict):\n",
    "    contraction_pattern= re.compile('({})'.format('|'.join(contraction_dict.keys())), flags= re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    def expand_match(contraction):\n",
    "        match= contraction.group(0)\n",
    "        first_char= match[0]\n",
    "        expanded_contraction= contraction_dict.get(match) \\\n",
    "            if contraction_dict.get(match) \\\n",
    "            else contraction_dict.get(match.lower())\n",
    "        expanded_contraction= expanded_contraction\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text= contraction_pattern.sub(expand_match, text)\n",
    "    expanded_text= re.sub(\"'\",\"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "def main_contraction(text):\n",
    "    text = expand_contraction(text, contractions_dict)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_number(text):\n",
    "    output = ''.join(c for c in text if not c.isdigit())\n",
    "    return output\n",
    "def remove_punct(text):\n",
    "    return \"\".join(c for c in text if c not in punctuation)\n",
    "def to_strip(text):\n",
    "    return \" \".join([c for c in text.split() if len(c)>2])\n",
    "def remove_char(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n",
    "    return text\n",
    "def remove_duplicate(text):\n",
    "    text = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", text)\n",
    "    return text \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words= stopwords.words('english')\n",
    "    return ' '.join(c for c in nltk.word_tokenize(text) if c not in stop_words)\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wordnet_lemma = WordNetLemmatizer()\n",
    "\n",
    "def lemma(text):\n",
    "    lemmatize_words = [wordnet_lemma.lemmatize(word) for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    return ' '.join(lemmatize_words)\n",
    "\n",
    "faq_quest['prep1']= faq_quest['Questions'].apply(to_lower)\n",
    "faq_quest['prep2']= faq_quest['prep1'].apply(main_contraction)\n",
    "faq_quest['prep3']= faq_quest['prep2'].apply(remove_number)\n",
    "faq_quest['prep4']= faq_quest['prep3'].apply(remove_punct)\n",
    "faq_quest['prep5']= faq_quest['prep4'].apply(to_strip)\n",
    "faq_quest['prep6']= faq_quest['prep5'].apply(remove_char)\n",
    "faq_quest['prep7']= faq_quest['prep6'].apply(remove_duplicate)\n",
    "faq_quest['prep8']= faq_quest['prep7'].apply(remove_stopwords)\n",
    "faq_quest['lemma']= faq_quest['prep8'].apply(lemma)\n",
    "faq_quest.head(10)\n",
    "\n",
    "faq_answ['prep1']= faq_answ['Answers'].apply(to_lower)\n",
    "faq_answ['prep2']= faq_answ['prep1'].apply(main_contraction)\n",
    "faq_answ['prep3']= faq_answ['prep2'].apply(remove_number)\n",
    "faq_answ['prep4']= faq_answ['prep3'].apply(remove_punct)\n",
    "faq_answ['prep5']= faq_answ['prep4'].apply(to_strip)\n",
    "faq_answ['prep6']= faq_answ['prep5'].apply(remove_char)\n",
    "faq_answ['prep7']= faq_answ['prep6'].apply(remove_duplicate)\n",
    "faq_answ['prep8']= faq_answ['prep7'].apply(remove_stopwords)\n",
    "faq_answ['lemma']= faq_answ['prep8'].apply(lemma)\n",
    "faq_answ.head(10)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label = LabelEncoder()\n",
    "faq['AnswersEncode'] = label.fit_transform(faq['Answers'])\n",
    "faq\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "text = faq['Questions']\n",
    "y= faq['AnswersEncode'].values\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(use_idf=True, analyzer='word', stop_words='english', token_pattern=r'\\b[^\\d\\W]+\\b', ngram_range=(1,2))\n",
    "X_train = tfidf.fit_transform(text)\n",
    "print(X_train)\n",
    "\n",
    "\n",
    "lsvc = LinearSVC(random_state = 2021)\n",
    "lsvc.fit(X_train, y)\n",
    "\n",
    "\n",
    "search_test = [\n",
    "    \"How can I recover?\",\n",
    "    \"Is cannabis dangerous?\",\n",
    "    \"What is the side effect of drinking?\"\n",
    "]\n",
    "\n",
    "search_engine = tfidf.transform(search_test)\n",
    "result = lsvc.predict(search_engine)\n",
    "\n",
    "for question in result:\n",
    "    faq_data = faq.loc[faq.isin([question]).any(axis=1)]\n",
    "    print(\"Answer: \", faq_data['Answers'].values)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
