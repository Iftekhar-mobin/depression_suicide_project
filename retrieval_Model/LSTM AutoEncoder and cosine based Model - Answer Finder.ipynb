{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ifte/amiebot_project/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import io\n",
    "import numpy as np\n",
    "import string\n",
    "import MeCab \n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, RepeatVector\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from six.moves import cPickle\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = MeCab.Tagger('-Owakati')\n",
    "\n",
    "p = Path(\"/home/ifte/amiebot_project/amie-HelpBot/mobicontrol_data/corpus_mobicontrol.csv\")\n",
    "df = pd.read_csv(p, header=0, usecols=[\"page\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    replaced_text = re.sub(r'[【】]', ' ', text)       # 【】の除去\n",
    "    replaced_text = re.sub(r'[・_]', '', replaced_text)       # ・ の除去\n",
    "    replaced_text = re.sub(r'[（）()]', ' ', replaced_text)     # （）の除去\n",
    "    replaced_text = re.sub(r'[［］\\[\\]]', ' ', replaced_text)   # ［］の除去\n",
    "    replaced_text = re.sub(r'[@＠]\\w+', '', replaced_text)  # メンションの除去\n",
    "    replaced_text = re.sub(r'https?:\\/\\/.*?[\\r\\n ]', '', replaced_text)  # URLの除去\n",
    "    replaced_text = re.sub(r'　', ' ', replaced_text)  # 全角空白の除去\n",
    "    replaced_text = re.sub(r'\\d+', '', replaced_text) # 数字の除去\n",
    "    replaced_text = re.sub(r'[-/。,、.=]', ' ', replaced_text)\n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_ja = []\n",
    "STOPWORD_FILE = Path(\"/home/ifte/amiebot_project/amie-HelpBot/amie_helpbot/\" + '/assets/learning/stopword_ja.txt')\n",
    "with open(STOPWORD_FILE, encoding='utf-8') as fr:\n",
    "    stop_words_ja = fr.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"page\"]]\n",
    "X = df[\"text\"].apply(lambda x: mecab.parse(x).strip(\"\\n\"))\n",
    "df['parsed'] = X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df.page.unique()\n",
    "c_size = 100\n",
    "\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for i in list(classes):\n",
    "    arr_index = df[df.page == i].parsed.values\n",
    "    data = ''.join(list(arr_index))\n",
    "    \n",
    "    all_data = clean_text(data)\n",
    "    \n",
    "    arr_words = np.array(all_data.split())\n",
    "    #print(arr_words) \n",
    "    \n",
    "    num = arr_words.shape[0]//c_size\n",
    "    full = c_size * num\n",
    "    rest = arr_words.shape[0] - full\n",
    "    \n",
    "    pad = np.zeros([c_size-rest], dtype=int)\n",
    "    sc = np.concatenate((arr_words,pad))\n",
    "    features = sc.reshape(num+1, c_size)\n",
    "    \n",
    "    df_v = pd.DataFrame(features)\n",
    "    df_v[\"cls\"] = i\n",
    "    \n",
    "    result = pd.concat([result, df_v]) \n",
    "\n",
    "    \n",
    "#print(result)\n",
    "#result.to_csv('processed.csv')\n",
    "\n",
    "\n",
    "# Splitting into fixed length however neural network works with fixed length input, \n",
    "# we need to define this length by getting rid or trimming inputs that are longer than this length\n",
    "# But we dont want to trim any information hence the above approach will work well\n",
    "#################################################\n",
    "#MAX_LEN = 20\n",
    "#train_data = train_data[train_data.Question.apply(lambda x: len(x.split())) < MAX_LEN]\n",
    "#################################################\n",
    "# data is cleaned which we did above\n",
    "#train_data.Question = train_data.Question.apply(lambda x: (re.sub('[^\\u0620-\\uFEF0\\s]', '', x)).strip())\n",
    "#################################################\n",
    "#We have to pad sequences that are shorter than MAX_LEN\n",
    "#train_data = pad_sequences(train_data, padding='post', truncating='post', maxlen=MAX_LEN)\n",
    "\n",
    "# Tokenization is the process of reading the text we have and creating a vocabulary based on some parameters, \n",
    "# then using this vocabulary we define an index where every word in the vocabulary has its ID.\n",
    "#################################################\n",
    "#tokenizer = Tokenizer(num_words=NUM_WORDS, lower=False)\n",
    "#tokenizer.fit_on_texts(train_data[\"Question\"].values)\n",
    "#train_data = tokenizer.texts_to_sequences(train_data[\"Question\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_cols = result.iloc[:,:-1]\n",
    "tog = Data_cols.apply(lambda x: ' '.join(x), axis=1)\n",
    "#tog = result.iloc[:,:].apply(lambda x: ' '.join(x), axis=1)\n",
    "sent = list(tog.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_WORDS = len(np.unique(Data_cols.values.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=NUM_WORDS, lower=False)\n",
    "tokenizer.fit_on_texts(tog.values)\n",
    "train_data = tokenizer.texts_to_sequences(tog.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pad_sequences(train_data, padding='post', truncating='post', maxlen=101, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 28,   1,  16, ..., 479,   9,   0],\n",
       "       [  1,  35,  33, ...,  59,   3,   0],\n",
       "       [  2,  59, 202, ...,   8, 148,   0],\n",
       "       ...,\n",
       "       [311, 312, 298, ..., 212,   4,   0],\n",
       "       [ 76,   2, 191, ...,  28,  25,   0],\n",
       "       [  1, 128,   8, ...,   6,   6,   0]], dtype=int32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)\n",
    "train_data.shape\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BATCH_SIZE = 32 # Batch size for GPU\n",
    "#MAX_LEN = 20 # Padding length (# of words)\n",
    "LSTM_EMBED = 10 # Number of LSTM nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "6873/6873 [==============================] - 177s 26ms/step - loss: 8.3560\n",
      "Epoch 2/3\n",
      "6873/6873 [==============================] - 189s 27ms/step - loss: 7.0895\n",
      "Epoch 3/3\n",
      "6873/6873 [==============================] - 190s 28ms/step - loss: 6.3625\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(NUM_WORDS, 100, input_length=101))\n",
    "model.add(LSTM(LSTM_EMBED, dropout=0.2, recurrent_dropout=0.2, input_shape=(train_data.shape[1], NUM_WORDS)))\n",
    "model.add(RepeatVector(train_data.shape[-1]))\n",
    "model.add(LSTM(LSTM_EMBED, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "model.add(Dense(NUM_WORDS, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "model.fit(train_data, np.expand_dims(train_data, -1), epochs=3, batch_size=101)\n",
    "\n",
    "model.save(\"lstm-encoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_learning_phase(False)\n",
    "#tokenizer = cPickle.load(open(\"lstm-autoencoder-tokenizer.pickle\", \"rb\"))\n",
    "# Read the encoder model\n",
    "#model = load_model(\"lstm-encoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the encoding function\n",
    "encode = K.function([model.input, K.learning_phase()], [model.layers[1].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Questions = np.squeeze(np.array(encode([train_data])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a question: \n",
      "IP connections\n"
     ]
    }
   ],
   "source": [
    "question = input('Please enter a question: \\n')\n",
    "#question = stemmer.stem(question)\n",
    "question = tokenizer.texts_to_sequences([question])\n",
    "question = pad_sequences(question, padding='post', truncating='post', maxlen=101)\n",
    "question = np.squeeze(encode([question]))\n",
    "\n",
    "rank = cosine_similarity(question.reshape(1, -1), Questions)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000001 1.0000001 1.0000001 ... 0.9999981 0.9999975 0.9999973]]\n"
     ]
    }
   ],
   "source": [
    "ranking = -np.sort(-rank)\n",
    "print(ranking)\n",
    "t = np.argsort(ranking, axis=1)\n",
    "top = t.reshape(-1,1)\n",
    "top10 = top[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6872],\n",
       "       [6871],\n",
       "       [6870],\n",
       "       [6869],\n",
       "       [6868],\n",
       "       [6867],\n",
       "       [6866],\n",
       "       [6865],\n",
       "       [6864],\n",
       "       [6863]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10[0:10]\n",
    "#print(np.sort(rank))\n",
    "# Sorting descendent order\n",
    "#top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6594],\n",
       "       [2086],\n",
       "       [1494],\n",
       "       [2762],\n",
       "       [4514]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10=np.argsort(rank, axis=-1).T[-5:]\n",
    "top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1992],\n",
       "       [3576],\n",
       "       [5947],\n",
       "       [ 660],\n",
       "       [2151],\n",
       "       [6594],\n",
       "       [2086],\n",
       "       [1494],\n",
       "       [2762],\n",
       "       [4514]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(rank, axis=-1).T[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PageID:  330 idx 6872 = の URL が 表示 さ れ ます SSL Cert MobiControl サーバ と の SSL 通信 の ため の 証明 書 の ファイル 名 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "\n",
      " ########## \n",
      "\n",
      "PageID:  330 idx 6871 = チェック を 入れ ます エージェント の 挙動 を ログ に 取り 後 に SOTI に 送り 問題 分析 を し て 貰い ます Connect Disconnect PC から MobiControl サーバ へ の 接続 または 切断 の アクション を 執る とき に この ボタン を 押し ます Status PC の 状況 を 表示 し ます Profile PC に 設定 さ れ て いる 構成 プロファイル の 名前 を 表示 し ます Events PC と MobiControl サーバ と の 交信 記録 Packages パッケージ スタジオ で 作成 し た アプリ の パッケージ 名 が 表示 さ れ ます Servers 接続 可能 な MobiControl サーバ\n",
      "\n",
      " ########## \n",
      "\n",
      "PageID:  330 idx 6870 = Co Ltd Tokyo タブ 説明 General Device Name MobiControl コンソール で の この PC で の 名前 です ここ で 名前 変更 を する こと が でき ます Allow Inboud TCP IP Connections これ に チェック を 入れる と PC が MobiControl サーバ に 接続 し て い なく て も コンソール 側 から PC に 接続 し て リモート 操作 を し て 貰え ます 但し コンソール と PC と の 間 に Firewall が ある と 接続 でき ませ ん Log to file Normally Off エージェント プログラム に 不具合 が ある 可能 性 が ある 場合 ここ に\n",
      "\n",
      " ########## \n",
      "\n",
      "PageID:  330 idx 6869 = 切断 の アクション を 執る とき に この ボタン を 押し ます Status PC の 状況 を 表示 し ます Profile PC に 設定 さ れ て いる 構成 プロファイル の 名前 を 表示 し ます Events PC と MobiControl サーバ と の 交信 記録 Packages パッケージ スタジオ で 作成 し た アプリ の パッケージ 名 が 表示 さ れ ます Servers 接続 可能 な MobiControl サーバ の URL が 表示 さ れ ます SSL Cert MobiControl サーバ と の SSL 通信 の ため の 証明 書 の ファイル 名 Copyright © SOTI Inc Canada Translated by Penetrate of Limits\n",
      "\n",
      " ########## \n",
      "\n",
      "PageID:  330 idx 6868 = これ に チェック を 入れる と PC が MobiControl サーバ に 接続 し て い なく て も コンソール 側 から PC に 接続 し て リモート 操作 を し て 貰え ます 但し コンソール と PC と の 間 に Firewall が ある と 接続 でき ませ ん Log to file Normally Off エージェント プログラム に 不具合 が ある 可能 性 が ある 場合 ここ に チェック を 入れ ます エージェント の 挙動 を ログ に 取り 後 に SOTI に 送り 問題 分析 を し て 貰い ます Connect Disconnect PC から MobiControl サーバ へ の 接続 または\n",
      "\n",
      " ########## \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in range(len(top10)):\n",
    "    #print(data['Answer'].iloc[item].values[0])\n",
    "    idx = top[item,0]\n",
    "    \n",
    "        # if the dataset file structure \"Quesition | Answer\" then use following line  \n",
    "        #print(data['Answer'].iloc[item].values[0])\n",
    "    print(\"PageID: \",result.iloc[idx,-1],\"idx\",idx,\"=\",tog.values[idx])\n",
    "    print(\"\\n ########## \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
