{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "model = load_facebook_model(datapath('/home/ubuntu/amie-HelpBot/amie_helpbot/model_test/cc.ja.300.bin'))\n",
    "\n",
    "with open('/home/ubuntu/amie-HelpBot/amie_helpbot/model_test/1810/data/processed_texts.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "new_sent = []\n",
    "[new_sent.append(i.split()) for i in lines]\n",
    "\n",
    "model.build_vocab(new_sent, update=True)\n",
    "model.train(sentences=new_sent, total_examples=len(new_sent), epochs=5)\n",
    "model.save('trained.300.bin')\n",
    "\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "w = Word2Vec.load(\"trained.300.bin\")\n",
    "word_vec = w.wv\n",
    "word_vec.save('trained_300.vec')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import common_texts, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "unpickling stack underflow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4075/2683837736.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/ifte-home/work/resources/w2v_300/model.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venvs/exp-Env/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/exp-Env/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \"\"\"\n\u001b[1;32m   1460\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# needed because loading from S3 doesn't support readline()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: unpickling stack underflow"
     ]
    }
   ],
   "source": [
    "k = KeyedVectors.load('/home/hduser_/Downloads/1810/trained_300.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bin model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '/home/ifte-home/work/resources/w2v_300/model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KeyedVectors.load_word2vec_format(file_name,binary=True,unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('employment', 0.6191103458404541),\n",
       " ('good-paying', 0.6184026002883911),\n",
       " ('well-paying', 0.6018323302268982),\n",
       " ('hire', 0.5959115028381348),\n",
       " ('high-paying', 0.5746860504150391),\n",
       " ('better-paying', 0.5539743900299072),\n",
       " ('higher-paying', 0.5278534293174744),\n",
       " ('hiring', 0.5177246928215027),\n",
       " ('employer', 0.5092951059341431),\n",
       " ('low-paying', 0.5059986114501953),\n",
       " ('work', 0.4979798495769501),\n",
       " ('payroll', 0.4976227283477783),\n",
       " ('position', 0.49209141731262207),\n",
       " ('low-skill', 0.4899776577949524),\n",
       " ('lower-paying', 0.4889904856681824),\n",
       " ('high-wage', 0.48775628209114075),\n",
       " ('low-skilled', 0.480994313955307),\n",
       " ('full-time', 0.4792312979698181),\n",
       " ('nonfarm', 0.4736497700214386),\n",
       " ('unemployed', 0.4703593850135803)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['job'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collect vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/hduser_/Downloads/1810/data/processed_texts.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_vector(text):\n",
    "    sum_vec = np.zeros(300)\n",
    "    word_count = 0\n",
    "    for items in text.split():\n",
    "        try: \n",
    "            temp = k.wv[items]\n",
    "        except KeyError:\n",
    "            temp = 0\n",
    "        sum_vec += temp\n",
    "        word_count += 1\n",
    "    return sum_vec / word_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iftekhar/amiebot/experiment_env/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "collect = []\n",
    "for items in lines:\n",
    "    collect.append(get_vector(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "def dump_to_file(file_path, data):\n",
    "    with open(file_path, 'wb') as output_file:\n",
    "        pickle.dump(data, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_to_file('vectors_300.pkl', collect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_from_text = word2vec.Word2Vec.load('/home/ifte/alechat_core/assets/wikipedia_w2v/en_wiki_w2v_dim_100_voc_1000000.model')  # C text format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_tmpfile(\"/home/ifte/alechat_core/assets/wikipedia_w2v/en_wiki_w2v_dim_100_voc_1000000.kv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"home/ifte/alechat_core/assets/wikipedia_w2v/en_wiki_w2v_dim_100_voc_1000000.model.wv\"\n",
    "wv_from_text.wv.save(path)\n",
    "# wv = KeyedVectors.load(\"model.wv\", mmap='r')\n",
    "# vector = wv['computer']  # numpy vector of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = word2vec.Word2Vec.load(\"/home/ifte/resource/wikiextractor/wikidata/wiki_w2v_dim_100_voc_1000000.model\") # これはダウンロードしたやつ\n",
    "# print(model.corpus_count)\n",
    "en_wiki_w2v_dim_100_voc_1000000.model.wv.vectors.npy\n",
    "en_wiki_w2v_dim_100_voc_1000000.model.wv.vectors.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = word2vec.Word2Vec.load(\"/home/ifte/resource/wikiextractor/wikidata/eng/en_wiki_w2v_dim_100_voc_1000000.model\") # これはダウンロードしたやつ\n",
    "model = word2vec.Word2Vec.load(\"/home/ifte/resource/wikiextractor/wikidata/eng/en_wiki_w2v_dim_100_voc_1000000.model\") # これはダウンロードしたやつ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KeyedVectors' object has no attribute 'wv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4075/157440835.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'job'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyedVectors' object has no attribute 'wv'"
     ]
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['job'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jobs', 0.7071852684020996),\n",
       " ('employment', 0.613107442855835),\n",
       " ('receptionist', 0.6007806658744812),\n",
       " ('employee', 0.5998069047927856),\n",
       " ('liking', 0.5908795595169067),\n",
       " ('coworker', 0.5703909993171692),\n",
       " ('quits', 0.5682342648506165),\n",
       " ('janitor', 0.567145824432373),\n",
       " ('assistant', 0.5660017728805542),\n",
       " ('fulltime', 0.5539208650588989),\n",
       " ('advice', 0.551762580871582),\n",
       " ('secretarial', 0.5490992069244385),\n",
       " ('quitting', 0.5443965196609497),\n",
       " ('intern', 0.541365385055542),\n",
       " ('waiter', 0.536011815071106),\n",
       " ('sabbatical', 0.5354043841362),\n",
       " ('opportunity', 0.5305323004722595),\n",
       " ('salary', 0.5269986987113953),\n",
       " ('jobless', 0.5267811417579651),\n",
       " ('assignment', 0.525550127029419)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['job'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.wv.most_similar(positive=['キャンペーン'], topn=20)\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "# model = KeyedVectors.load_word2vec_format('/home/ifte/resource/wikiextractor/cc.ja.300.vec')\n",
    "model = KeyedVectors.load_word2vec_format('/home/ifte/resource/wikiextractor/wikidata/eng')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
