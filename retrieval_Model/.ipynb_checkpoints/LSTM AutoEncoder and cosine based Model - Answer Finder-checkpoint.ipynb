{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import random\n",
    "import io\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import MeCab \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = MeCab.Tagger('-Owakati')\n",
    "\n",
    "p = Path(\"/home/ifte/Downloads/mobicontrol_data/corpus_mobicontrol.csv\")\n",
    "df = pd.read_csv(p, header=0, usecols=[\"page\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword Matching\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "\n",
    "def greeting(sentence):\n",
    "    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    replaced_text = re.sub(r'[【】]', ' ', text)       # 【】の除去\n",
    "    replaced_text = re.sub(r'[・_]', '', replaced_text)       # ・ の除去\n",
    "    replaced_text = re.sub(r'[（）()]', ' ', replaced_text)     # （）の除去\n",
    "    replaced_text = re.sub(r'[［］\\[\\]]', ' ', replaced_text)   # ［］の除去\n",
    "    replaced_text = re.sub(r'[@＠]\\w+', '', replaced_text)  # メンションの除去\n",
    "    replaced_text = re.sub(r'https?:\\/\\/.*?[\\r\\n ]', '', replaced_text)  # URLの除去\n",
    "    replaced_text = re.sub(r'　', ' ', replaced_text)  # 全角空白の除去\n",
    "    replaced_text = re.sub(r'\\d+', '', replaced_text) # 数字の除去\n",
    "    replaced_text = re.sub(r'[-/。,、.=]', ' ', replaced_text)\n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_ja = []\n",
    "STOPWORD_FILE = Path(\"/home/ifte/amiebot_project/amie-HelpBot/amie_helpbot/\" + '/assets/learning/stopword_ja.txt')\n",
    "with open(STOPWORD_FILE, encoding='utf-8') as fr:\n",
    "    stop_words_ja = fr.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"page\"]]\n",
    "X = df[\"text\"].apply(lambda x: mecab.parse(x).strip(\"\\n\"))\n",
    "df['parsed'] = X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df.page.unique()\n",
    "c_size = 100\n",
    "\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for i in list(classes):\n",
    "    arr_index = df[df.page == i].parsed.values\n",
    "    data = ''.join(list(arr_index))\n",
    "    \n",
    "    all_data = clean_text(data)\n",
    "    \n",
    "    arr_words = np.array(all_data.split())\n",
    "    #print(arr_words) \n",
    "    \n",
    "    num = arr_words.shape[0]//c_size\n",
    "    full = c_size * num\n",
    "    rest = arr_words.shape[0] - full\n",
    "    \n",
    "    pad = np.zeros([c_size-rest], dtype=int)\n",
    "    sc = np.concatenate((arr_words,pad))\n",
    "    features = sc.reshape(num+1, c_size)\n",
    "    \n",
    "    df_v = pd.DataFrame(features)\n",
    "    df_v[\"cls\"] = i\n",
    "    \n",
    "    result = pd.concat([result, df_v]) \n",
    "\n",
    "    \n",
    "#print(result)\n",
    "#result.to_csv('processed.csv')\n",
    "\n",
    "\n",
    "# Splitting into fixed length\n",
    "#################################################\n",
    "#MAX_LEN = 20\n",
    "#train_data = train_data[train_data.Question.apply(lambda x: len(x.split())) < MAX_LEN]\n",
    "#################################################\n",
    "# data is cleaned \n",
    "#train_data.Question = train_data.Question.apply(lambda x: (re.sub('[^\\u0620-\\uFEF0\\s]', '', x)).strip())\n",
    "#################################################\n",
    "#We have to pad sequences that are shorter than MAX_LEN\n",
    "#train_data = pad_sequences(train_data, padding='post', truncating='post', maxlen=MAX_LEN)\n",
    "\n",
    "# Tokenization is the process of reading the text we have and creating a vocabulary based on some parameters, \n",
    "# then using this vocabulary we define an index where every word in the vocabulary has its ID.\n",
    "#################################################\n",
    "#tokenizer = Tokenizer(num_words=NUM_WORDS, lower=False)\n",
    "#tokenizer.fit_on_texts(train_data[\"Question\"].values)\n",
    "#train_data = tokenizer.texts_to_sequences(train_data[\"Question\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_cols = result.iloc[:,:-1]\n",
    "tog = Data_cols.apply(lambda x: ' '.join(x), axis=1)\n",
    "#tog = result.iloc[:,:].apply(lambda x: ' '.join(x), axis=1)\n",
    "sent = list(tog.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, RepeatVector\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stop_words_ja)\n",
    "vectorizer.fit(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a question: \n",
      "google\n"
     ]
    }
   ],
   "source": [
    "# Read a question from the user\n",
    "question = [input('Please enter a question: \\n')]\n",
    "question = vectorizer.transform(question)\n",
    "\n",
    "# Rank all the questions using cosine similarity to the input question\n",
    "rank = cosine_similarity(question, vectorizer.transform(sent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3641 = Mode で は だけ が 表示 さ れ これ を タップ し て も managed Google Play ストア に しか アクセス でき ませ ん managed Google Play ストア の URL は https : play google com work です managed Google Play ストア の アプリ は 管理 者 用 Google アカウント 保有 者 が 承認 し 掲示 し ます 詳しく は 業務 アプリ の 配布 インストール を 参照 ください Copyright © SOTI Inc Canada Translated by Penetrate of Limits Co Ltd Tokyo 管理 者 用 Google アカウント 端末 または 端末 ユーザ の Google アカウント G Suite アカウント または managed Google アカウント\n",
      "\n",
      " ########## \n",
      "\n",
      "4205 = の メールアドレス と パスワード を 入力 し ます 端末 登録 ルール の Android Management で 「 managed Google Account 」 を 選ぶ 前提 として 組織 団体 の AD を Google を 同期 さ せ て おき ます 従って Google は AD DS の アカウント を Google アカウント として 認識 でき ます 詳しく は Android Enterprise の Google アカウント を 参照 ください 図 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "\n",
      " ########## \n",
      "\n",
      "3653 = 使っ て Android Enterprise 端末 を 管理 する 場合 に は 会社 団体 の AD DS の データベース を GCDS Google Cloud Directory Sync ツール を 使っ て Google の アカウント データベース と 連動 さ せ て おき ます 図 A 管理 者 用 Google アカウント と 端末 または 端末 ユーザ の Google アカウント の 関係 Android Enterprise 端末 で は 端末 または 端末 ユーザ の Google アカウント が 必要 です 端末 ユーザ の 私的 な Google アカウント で は managed Google Play ストア から アプリ を ダウンロード でき ませ ん 管理 者 用 Google アカウント 端末 または 端末 ユーザ\n",
      "\n",
      " ########## \n",
      "\n",
      "3625 = Google Play ストア に アクセス する に は 端末 または 端末 ユーザ の Google アカウント が 必要 です 端末 ユーザ の 私的 な Google アカウント で は managed Google Play ストア から アプリ を ダウンロード でき ませ ん 管理 者 用 Google アカウント 端末 または 端末 ユーザ の Google アカウント G Suite アカウント または managed Google アカウント 端末 ユーザ の AD DS の アカウント を Google アカウント として 使用 managed Google Play アカウント 端末 を MobiControl に 登録 する 際 に 発行 さ れ 端末 に 埋め込ま れる 詳しく は Android Enterprise と Google アカウント を 参照 ください A managed\n",
      "\n",
      " ########## \n",
      "\n",
      "3626 = Google Play アカウント と 端末 ユーザ の Google アカウント managed Google Play アカウント で managed Google Play ストア を 管理 する 場合 従業 員 の Android Enterprise 端末 の Google アカウント は MobiControl に 登録 する とき に 発行 さ れ 端末 に 埋め込ま れ ます 図 A 管理 者 用 Google アカウント の パスワード Google アカウント の ID 部分 は メールアドレス の 形式 です 管理 者 用 Google アカウント に は 実在 する メールアドレス を 使い ます Google アカウント に 従属 する パスワード の 決定 方法 は 次 の 通り です Gmail の メールアドレス を Google アカウント と する\n",
      "\n",
      " ########## \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grab the top 5\n",
    "top = np.argsort(rank, axis=-1).T[-5:]\n",
    "#print(top)\n",
    "\n",
    "# Print top 5\n",
    "for item in range(len(top)):\n",
    "    idx = top[item,0]\n",
    "    \n",
    "    # if the dataset file structure \"Quesition | Answer\" then use following line  \n",
    "    #print(data['Answer'].iloc[item].values[0])\n",
    "    print(idx,\"=\",tog.values[idx])\n",
    "    print(\"\\n ########## \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
