{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import random\n",
    "import io\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import MeCab \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = MeCab.Tagger('-Owakati')\n",
    "\n",
    "#p = Path(\"/home/ifte/amiebot_project/amie-HelpBot/mobicontrol_data/corpus_mobicontrol.csv\")\n",
    "df = pd.read_csv(\"/home/ifte/amiebot_project/Large_files/mobicontrol_data/Train_Test_Data/japanese/corpus_ver14.csv\", \n",
    "                 header=0, usecols=[\"page\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_ja = []\n",
    "STOPWORD_FILE = Path(\"/home/ifte/amiebot_project/amie-HelpBot/amie_helpbot/\" + '/assets/learning/stopword_ja.txt')\n",
    "with open(STOPWORD_FILE, encoding='utf-8') as fr:\n",
    "    stop_w = fr.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist = ['ます', '端末', 'する', '設定', '表示', 'mobicontrol', '選択', '入力', 'アプリ', 'ユーザ', '構成', 'でき', \n",
    "           '画面', '接続', 'ルール', 'ない', 'インストール', 'です', '指定', '管理', 'ad', 'ください', 'この', 'クリック', \n",
    "           '参照', 'ボタン', 'あり', 'チェック', 'コンソール', 'または', '証明', 'id', '項目', 'なり', 'アクセス',\n",
    "           'データ', '対象', '適用', 'いる', 'pc', 'その','れる','として','時刻','url',' 更新','押す','利用','ds','できる',\n",
    "          'フォルダ', 'ある']\n",
    "stop_words_ja = stop_w #+ newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    replaced_text = re.sub(r'[【】]', ' ', text)       # 【】の除去\n",
    "    replaced_text = re.sub(r'[・_]', '', replaced_text)       # ・ の除去\n",
    "    replaced_text = re.sub(r'[（）()]', ' ', replaced_text)     # （）の除去\n",
    "    replaced_text = re.sub(r'[［］\\[\\]]', ' ', replaced_text)   # ［］の除去\n",
    "    replaced_text = re.sub(r'[@＠]\\w+', '', replaced_text)  # メンションの除去\n",
    "    replaced_text = re.sub(r'https?:\\/\\/.*?[\\r\\n ]', '', replaced_text)  # URLの除去\n",
    "    replaced_text = re.sub(r'　', ' ', replaced_text)  # 全角空白の除去\n",
    "    replaced_text = re.sub(r'\\d+', '', replaced_text) # 数字の除去\n",
    "    replaced_text = re.sub(r'[-/。,、.=]', ' ', replaced_text)\n",
    "    \n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words_ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"page\"]]\n",
    "X = df[\"text\"].apply(lambda x: mecab.parse(x).strip(\"\\n\"))\n",
    "df['parsed'] = X \n",
    "\n",
    "classes = df.page.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict = {}\n",
    "\n",
    "for i in list(classes):\n",
    "    page_content = df[df.page == i].parsed.values\n",
    "    data = ''.join(list(page_content))\n",
    "    Dict[i] = [data]\n",
    "    \n",
    "d = pd.DataFrame.from_dict(Dict,orient='index', columns=['Data'])\n",
    "d['PageID'] = d.index\n",
    "sent = list(d.Data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1), stop_words=stop_words_ja, max_df=0.98)\n",
    "vectors = vectorizer.fit_transform(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=0.98, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True,\n",
       "                stop_words=['あそこ', 'あたり', 'あちら', 'あっち', 'あと', 'あな', 'あなた', 'あれ',\n",
       "                            'いくつ', 'いつ', 'いま', 'いや', 'いろいろ', 'うち', 'おおまか',\n",
       "                            'おまえ', 'おれ', 'がい', 'かく', 'かたち', 'かやの', 'から', 'がら',\n",
       "                            'きた', 'くせ', 'ここ', 'こっち', 'こと', 'ごと', 'こちら', ...],\n",
       "                strip_accents=None, sublinear_tf=False,\n",
       "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<445x5964 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 82062 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idf score \n",
    "#idf = vectorizer.idf_\n",
    "# visulalize idf score\n",
    "#print(dict(zip(vectorizer.get_feature_names(), idf)))\n",
    "\n",
    "weights = np.asarray(vectors.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term': vectorizer.get_feature_names(), 'weight': weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "TermsWeight = weights_df.sort_values(by='weight', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5272         端末\n",
       "5533         設定\n",
       "2643        サーバ\n",
       "5449         表示\n",
       "3210     プロファイル\n",
       "5147         登録\n",
       "2297        アプリ\n",
       "5788         選択\n",
       "4870         構成\n",
       "3780         入力\n",
       "2554       グループ\n",
       "3335        ユーザ\n",
       "2093         でき\n",
       "3062       ファイル\n",
       "5115         画面\n",
       "5566         認証\n",
       "4621         接続\n",
       "3404        ルール\n",
       "3012      パスワード\n",
       "5548         証明\n",
       "4597         指定\n",
       "1846    windows\n",
       "5280         管理\n",
       "2119         ない\n",
       "2098         です\n",
       "2365     インストール\n",
       "2254      アカウント\n",
       "2585      コンソール\n",
       "1977       ください\n",
       "2039         その\n",
       "2259       アクセス\n",
       "2537       クリック\n",
       "3691         作成\n",
       "301     android\n",
       "1985         この\n",
       "256          ad\n",
       "3320        メール\n",
       "3986         参照\n",
       "1297         pc\n",
       "2832       チェック\n",
       "2894        データ\n",
       "1084      macos\n",
       "2440     エージェント\n",
       "5926         項目\n",
       "3250        ボタン\n",
       "1915         あり\n",
       "901          id\n",
       "2690      スクリプト\n",
       "2190        または\n",
       "2290       アドレス\n",
       "Name: term, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TermsWeight.term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = d.Data.values[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'端末 の 機能 制限 MobiControl v 14 Manual 端末 機能 と コンテンツ の 制限 端末 の 機能 または 、 利用 できる データ 種類 に関して 制限 を 加える こと が'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.Data.values[idx][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(unicode_string):\n",
    "    tagger = MeCab.Tagger('-d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd')\n",
    "    node = tagger.parseToNode(unicode_string)\n",
    "\n",
    "    words = []\n",
    "    nouns = []\n",
    "    verbs = []\n",
    "\n",
    "    while node:\n",
    "        pos = node.feature.split(\",\")[0]\n",
    "        #print(pos + ' ' + node.feature)\n",
    "        \n",
    "        word = node.feature.split(\",\")[-3]\n",
    "        if pos == \"名詞\":\n",
    "            nouns.append(word)\n",
    "        elif pos == \"??\":\n",
    "            verbs.append(word)\n",
    "        \n",
    "        words.append(word)\n",
    "        node = node.next\n",
    "    parsed_words_dict = {\n",
    "        \"all\": words[1:-1], # ??????????????????\n",
    "        \"nouns\": nouns,\n",
    "        \"verbs\": verbs,\n",
    "        }\n",
    "    return parsed_words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': ['ランチャー', 'で', '表示', 'する', 'れる', 'iKON', 'を', '変更', 'する', 'たい'],\n",
       " 'nouns': ['ランチャー', '表示', 'iKON', '変更'],\n",
       " 'verbs': []}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse('ランチャーで表示されるアイコンを変更したい')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-121-518e64145285>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-121-518e64145285>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    def cleaning(text, stop_words):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Developed Tagger Parser\n",
    "\tdef cleaning(text, stop_words):\n",
    "\t\t# 形態素解析\n",
    "\t\ttagger = MeCab.Tagger('-d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd')\n",
    "\t\ttagger.parse(\"\")\n",
    "\t\tres = tagger.parseToNode(text.lower())\n",
    "\t\tstr_out = ''\n",
    "\t\t\n",
    "\t\twhile res:\n",
    "\t\t\tarr = res.feature.split(\",\")\n",
    "\t\t\n",
    "\t\t\t# 辞書に登録されている名詞のみ\n",
    "\t\t\tif not arr == None and len(arr) > 7 and arr[0] == '名詞':\n",
    "\t\t\t\tword = arr[6].lower()\n",
    "\t\t\t\t\n",
    "\t\t\t\t# 数値、ストップワード、アルファベット1文字は除外\n",
    "\t\t\t\tif not arr[1] == '数' and not word in stop_words and \\\n",
    "\t\t\t\t\tnot (len(word) == 1 and re.search(r\"[a-xA-Z0-9]\", word) is not None):\n",
    "\t\t\t\t\tstr_out += word + ' '\n",
    "\t\t\tres = res.next\n",
    "\t\t\n",
    "\t\treturn str_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a question: \n",
      "iMessage\n",
      "PageID:  1 idx 1\n",
      "##########\n",
      "PageID:  430 idx 430\n",
      "##########\n",
      "PageID:  271 idx 271\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "# Read a question from the user\n",
    "question = input('Please enter a question: \\n')\n",
    "\n",
    "parsed_question = cleaning(question, stop_words_ja)\n",
    "parsed_question = parsed_question.strip(\"\\n\").rstrip()\n",
    "\n",
    "q = vectorizer.transform([parsed_question])\n",
    "\n",
    "# Rank all the questions using cosine similarity to the input question\n",
    "rank = cosine_similarity(q, vectorizer.transform(sent))\n",
    "\n",
    "# Grab the top 5\n",
    "top = np.argsort(rank, axis=-1).T[-3:]\n",
    "#print(top)\n",
    "\n",
    "for item in range(len(top)):\n",
    "    idx = top[item,0]\n",
    "    \n",
    "    # if the dataset file structure \"Quesition | Answer\" then use following line  \n",
    "    print(\"PageID: \",d.iloc[idx,-1],\"idx\",idx)\n",
    "    #print(\"PageID: \",d.iloc[idx,-1],\"idx\",idx,\"=\",d.Data.values[idx])\n",
    "    print(\"##########\")\n",
    "    #print(\"PageID:\",d.iloc[idx,-1],\"idx\",idx,\"=\",d.Data.values[idx][0:300])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
