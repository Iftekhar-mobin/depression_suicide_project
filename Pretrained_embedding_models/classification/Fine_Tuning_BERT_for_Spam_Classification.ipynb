{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFOTiqrtNvyy"
   },
   "source": [
    "# Install Transformers Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hkhc10wNrGt"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "x4giRzM7NtHJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "# specify GPU\n",
    "# device = torch.device(\"cuda\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKd-Tj3hOMsZ"
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.preprocess_generate_dataset import generate_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_dataframe(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "cwJrQFQgN_BE",
    "outputId": "854f0b55-e330-4806-cc32-79643e6bd721"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"spamdata_v2.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={'Post': 'text', 'code': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>viable option youll leaving wife behind youd p...</td>\n",
       "      <td>Supportive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hard appreciate notion could meet someone else...</td>\n",
       "      <td>Ideation</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hi last night wa sitting ledge window contempl...</td>\n",
       "      <td>Behavior</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tried kill self failed badly cause moment want...</td>\n",
       "      <td>Attempt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi nem3030 sort thing enjoy personally always ...</td>\n",
       "      <td>Ideation</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Eccrine hidrocystoma of skin Eccrine dermal d...</td>\n",
       "      <td>Indicator</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Addicted to cannabis Cannabis addiction pain ...</td>\n",
       "      <td>Indicator</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Infectious disease of central nervous system ...</td>\n",
       "      <td>Indicator</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>previously asexual.1 Adult gender identity di...</td>\n",
       "      <td>Indicator</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Familial glomus tumor of skin Myopericytoma o...</td>\n",
       "      <td>Indicator</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>616 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text       Label  label\n",
       "0   viable option youll leaving wife behind youd p...  Supportive      4\n",
       "1   hard appreciate notion could meet someone else...    Ideation      2\n",
       "2   hi last night wa sitting ledge window contempl...    Behavior      1\n",
       "3   tried kill self failed badly cause moment want...     Attempt      0\n",
       "4   hi nem3030 sort thing enjoy personally always ...    Ideation      2\n",
       "..                                                ...         ...    ...\n",
       "46   Eccrine hidrocystoma of skin Eccrine dermal d...   Indicator      3\n",
       "73   Addicted to cannabis Cannabis addiction pain ...   Indicator      3\n",
       "6    Infectious disease of central nervous system ...   Indicator      3\n",
       "23   previously asexual.1 Adult gender identity di...   Indicator      3\n",
       "57   Familial glomus tumor of skin Myopericytoma o...   Indicator      3\n",
       "\n",
       "[616 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "676DPU1BOPdp",
    "outputId": "075808af-7b2e-4f0d-e888-e06e2e8abbf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.316558\n",
       "3    0.285714\n",
       "4    0.175325\n",
       "1    0.137987\n",
       "0    0.084416\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check class distribution\n",
    "df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKfWnApvOoE7"
   },
   "source": [
    "# Split train dataset into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "mfhSPF5jOWb7"
   },
   "outputs": [],
   "source": [
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "# we will use temp_text and temp_labels to create validation and test set\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3      tried kill self failed badly cause moment want...\n",
       "454    always something left even everything feel hop...\n",
       "13     one question whatre interest specific please p...\n",
       "2      hi last night wa sitting ledge window contempl...\n",
       "43     seems fun someone would ive never cared travel...\n",
       "                             ...                        \n",
       "309    make anxiety mental depression bitch seriously...\n",
       "89     look dont understand keep positive dont know l...\n",
       "497    sound really weird maybe distractibility somet...\n",
       "102    dont think sacrifice wouldnt right wrong under...\n",
       "307    thank sharing proved another rough night wa da...\n",
       "Name: text, Length: 431, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 2, 1, 0, 4, 2, 2, 4, 3, 1, 4, 1, 0, 1, 1, 3, 1, 3, 2, 4, 3,\n",
       "       0, 3, 2, 3, 1, 1, 4, 3, 2, 1, 2, 2, 1, 3, 0, 3, 3, 3, 4, 4, 2, 3,\n",
       "       2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 0, 3, 2, 1, 4, 4, 1, 2, 3, 0, 3, 3,\n",
       "       2, 2, 1, 4, 4, 2, 3, 2, 1, 1, 4, 2, 2, 1, 3, 3, 3, 2, 4, 4, 0, 0,\n",
       "       3, 1, 2, 1, 3, 3, 4, 2, 4, 4, 0, 4, 4, 3, 2, 1, 3, 2, 3, 2, 2, 2,\n",
       "       1, 2, 1, 3, 3, 2, 2, 3, 4, 4, 0, 2, 2, 4, 0, 3, 2, 2, 3, 2, 3, 2,\n",
       "       3, 2, 4, 2, 1, 2, 3, 3, 3, 3, 1, 4, 3, 3, 4, 3, 3, 2, 1, 2, 0, 2,\n",
       "       1, 4, 3, 4, 3, 1, 4, 3, 4, 2, 2, 4, 2, 3, 0, 2, 0, 4, 4, 4, 1, 0,\n",
       "       3, 2, 2, 3, 4, 3, 3, 3, 4, 3, 2, 2, 1, 0, 3, 2, 2, 2, 2, 4, 3, 1,\n",
       "       0, 4, 3, 3, 3, 3, 3, 4, 1, 1, 4, 1, 2, 3, 1, 0, 3, 3, 1, 1, 1, 3,\n",
       "       3, 2, 3, 3, 2, 2, 2, 1, 1, 1, 0, 2, 0, 2, 4, 3, 2, 2, 0, 2, 4, 3,\n",
       "       2, 4, 2, 2, 4, 0, 3, 2, 2, 3, 3, 4, 2, 4, 3, 2, 3, 2, 4, 2, 2, 3,\n",
       "       1, 2, 0, 4, 2, 2, 2, 2, 2, 3, 1, 3, 1, 4, 4, 0, 2, 3, 3, 2, 3, 3,\n",
       "       3, 4, 2, 2, 3, 4, 3, 2, 3, 4, 3, 0, 0, 3, 2, 1, 2, 1, 1, 3, 2, 3,\n",
       "       4, 3, 2, 4, 3, 4, 2, 2, 2, 3, 2, 3, 3, 4, 3, 2, 3, 3, 1, 4, 4, 0,\n",
       "       0, 2, 4, 3, 1, 2, 3, 2, 3, 2, 0, 3, 3, 4, 4, 3, 3, 3, 2, 2, 2, 2,\n",
       "       0, 2, 2, 2, 3, 4, 3, 1, 2, 3, 3, 4, 4, 2, 4, 2, 2, 4, 1, 3, 4, 1,\n",
       "       3, 3, 2, 4, 2, 1, 2, 4, 3, 4, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 3, 4,\n",
       "       2, 0, 3, 2, 1, 1, 3, 2, 2, 2, 3, 0, 1, 3, 4, 2, 4, 0, 1, 1, 2, 3,\n",
       "       3, 3, 0, 0, 3, 2, 4, 3, 1, 3, 4, 2, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(train_labels.values)\n",
    "y_test = to_categorical(test_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,TFBertModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(‘bert-base-cased’)\n",
    "bert = TFBertModel.from_pretrained(‘bert-base-cased’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7hsdLoCO7uB"
   },
   "source": [
    "# Import BERT Model and BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, TFDistilBertModel, DistilBertConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164,
     "referenced_widgets": [
      "983fea7c2dc74dfaba7aa60147af85d1",
      "ccf5f7e5cc10493ca9c44b14fdec31dc",
      "59bae99ad63d4a3a8b8d622d95f7ad07",
      "689e66a8dff249449b5f0f5bbfffa037",
      "49dd79a9a65044ba8345deb250ce4b24",
      "47862cd626cf46619a5cc505fde02276",
      "cb5f7a2a5bcb47649703cc633f2fb685",
      "6d2355752eb74f348596a380d2347b73",
      "0e580433bec2453da54c0ce9ee027401",
      "bdfd7634b8bf42aa8794ada8d9e47173",
      "73fc7587f1bb49df8a0fc87ecfac7f3c",
      "4da1c15300b2468ab1a7e2df800ed39b",
      "645d520e8a1c4f1fa202c6c68c5ce6af",
      "3bb6b624b4ce4be788c38cb8d1936177",
      "ed9f97f9d12a49aa939b7595ad3cb27c",
      "88214abee8b9462f86369072d858ae9f",
      "b4bef5a685954e238b52c43eefe4c9e5",
      "94264f36ceb64d3881fed952bf579072",
      "8cf06dad410440f78c50e3527e858905",
      "edf0e4c1ae214a66abb717b20e3bffad",
      "4d56a47453914de3be15d7a515e5b210",
      "6831c2b733d74b31a41cb6eb971a25d7",
      "58cd585c531444a5b8613c2d85bab022",
      "b6423c858927455e8cbc5a953273466a"
     ]
    },
    "id": "S1kY3gZjO2RE",
    "outputId": "4194574c-05d6-4d1d-c4c0-8dd89913ff79"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ifte-home/.cache/huggingface/hub/models--bert-base-uncased/refs/main'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4191/3867405138.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# MODEL_NAME = 'distilbert-base-uncased'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# import BERT-base pretrained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load the BERT tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/exp-Env/lib/python3.7/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             )\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/exp-Env/lib/python3.7/site-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_or_path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mtrust_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trust_remote_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/exp-Env/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0moriginal_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/exp-Env/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                     \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m                     \u001b[0msubfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m                     \u001b[0m_commit_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommit_hash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m                 )\n\u001b[1;32m    628\u001b[0m                 \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_commit_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_config_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommit_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/exp-Env/lib/python3.7/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mresume_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         )\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/exp-Env/lib/python3.7/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m             )\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/exp-Env/lib/python3.7/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0mref_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"refs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m                 \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ifte-home/.cache/huggingface/hub/models--bert-base-uncased/refs/main'"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'bert-base-uncased'\n",
    "# MODEL_NAME = 'distilbert-base-uncased'\n",
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME) # Loading the tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "_zOKeOMeO-DT"
   },
   "outputs": [],
   "source": [
    "# sample data\n",
    "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
    "\n",
    "# encode text\n",
    "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "oAH73n39PHLw",
    "outputId": "17b76300-71f2-464c-90b0-a5907f4f675a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "# output\n",
    "print(sent_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wIYaWI_Prg8"
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "yKwbpeN_PMiu",
    "outputId": "9f843240-6cf4-46c9-80b7-dc9ab4e03602"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "OXcswEIRPvGe"
   },
   "outputs": [],
   "source": [
    "max_seq_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "tk5S7DWaP2t6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ifte-home/venvs/exp-Env/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2342: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input (takes some time) \n",
    "# here tokenizer using from bert-base-cased\n",
    "x_train = tokenizer(\n",
    "    text=df.head(len(df) - 30).text.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=70,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "x_test = tokenizer(\n",
    "    text=df.tail(30).text.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=70,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = x_train['input_ids']\n",
    "attention_mask = x_train['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(586, 70), dtype=int32, numpy=\n",
       "array([[  101, 14874,  5724, ...,  2017,  3363,   102],\n",
       "       [  101,  2524,  9120, ...,  3291,  2116,   102],\n",
       "       [  101,  7632,  2197, ...,  2123,  2102,   102],\n",
       "       ...,\n",
       "       [  101,  5399, 26651, ...,  3345,  3162,   102],\n",
       "       [  101,  7667,  2478, ...,  1015, 28322,   102],\n",
       "       [  101,  1051, 10841, ..., 11265, 10976,   102]], dtype=int32)>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4191/3961141635.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalMaxPool1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/exp-Env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/exp-Env/lib/python3.7/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "\n",
    "max_len = 70\n",
    "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "embeddings = bert(input_ids,attention_mask = input_mask)[0] \n",
    "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "out = Dense(128, activation='relu')(out)\n",
    "out = tf.keras.layers.Dropout(0.1)(out)\n",
    "out = Dense(32,activation = 'relu')(out)\n",
    "y = Dense(6,activation = 'sigmoid')(out)\n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
    "model.layers[2].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wsm8bkRZQTw9"
   },
   "source": [
    "# Convert Integer Sequences to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "QR-lXwmzQPd6"
   },
   "outputs": [],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "# for validation set\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "# for test set\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2699,  3102,  ...,  2507,  4608,   102],\n",
       "        [  101,  2467,  2242,  ...,  2428,  3475,   102],\n",
       "        [  101,  2028,  3160,  ..., 16103,  2135,   102],\n",
       "        ...,\n",
       "        [  101,  2614,  2428,  ..., 18355,  3266,   102],\n",
       "        [  101,  2123,  2102,  ...,  2292,  2894,   102],\n",
       "        [  101,  4067,  6631,  ...,  5248,  2215,   102]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ov1cOBlcRLuk"
   },
   "source": [
    "# Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "qUy9JKFYQYLp"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101,  2699,  3102,  ...,  2507,  4608,   102],\n",
       "         [  101,  2467,  2242,  ...,  2428,  3475,   102],\n",
       "         [  101,  2028,  3160,  ..., 16103,  2135,   102],\n",
       "         ...,\n",
       "         [  101,  2614,  2428,  ..., 18355,  3266,   102],\n",
       "         [  101,  2123,  2102,  ...,  2292,  2894,   102],\n",
       "         [  101,  4067,  6631,  ...,  5248,  2215,   102]]),\n",
       " tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1]]),\n",
       " tensor([0, 4, 2, 1, 0, 4, 2, 2, 4, 3, 1, 4, 1, 0, 1, 1, 3, 1, 3, 2, 4, 3, 0, 3,\n",
       "         2, 3, 1, 1, 4, 3, 2, 1, 2, 2, 1, 3, 0, 3, 3, 3, 4, 4, 2, 3, 2, 2, 2, 2,\n",
       "         3, 2, 2, 2, 1, 2, 0, 3, 2, 1, 4, 4, 1, 2, 3, 0, 3, 3, 2, 2, 1, 4, 4, 2,\n",
       "         3, 2, 1, 1, 4, 2, 2, 1, 3, 3, 3, 2, 4, 4, 0, 0, 3, 1, 2, 1, 3, 3, 4, 2,\n",
       "         4, 4, 0, 4, 4, 3, 2, 1, 3, 2, 3, 2, 2, 2, 1, 2, 1, 3, 3, 2, 2, 3, 4, 4,\n",
       "         0, 2, 2, 4, 0, 3, 2, 2, 3, 2, 3, 2, 3, 2, 4, 2, 1, 2, 3, 3, 3, 3, 1, 4,\n",
       "         3, 3, 4, 3, 3, 2, 1, 2, 0, 2, 1, 4, 3, 4, 3, 1, 4, 3, 4, 2, 2, 4, 2, 3,\n",
       "         0, 2, 0, 4, 4, 4, 1, 0, 3, 2, 2, 3, 4, 3, 3, 3, 4, 3, 2, 2, 1, 0, 3, 2,\n",
       "         2, 2, 2, 4, 3, 1, 0, 4, 3, 3, 3, 3, 3, 4, 1, 1, 4, 1, 2, 3, 1, 0, 3, 3,\n",
       "         1, 1, 1, 3, 3, 2, 3, 3, 2, 2, 2, 1, 1, 1, 0, 2, 0, 2, 4, 3, 2, 2, 0, 2,\n",
       "         4, 3, 2, 4, 2, 2, 4, 0, 3, 2, 2, 3, 3, 4, 2, 4, 3, 2, 3, 2, 4, 2, 2, 3,\n",
       "         1, 2, 0, 4, 2, 2, 2, 2, 2, 3, 1, 3, 1, 4, 4, 0, 2, 3, 3, 2, 3, 3, 3, 4,\n",
       "         2, 2, 3, 4, 3, 2, 3, 4, 3, 0, 0, 3, 2, 1, 2, 1, 1, 3, 2, 3, 4, 3, 2, 4,\n",
       "         3, 4, 2, 2, 2, 3, 2, 3, 3, 4, 3, 2, 3, 3, 1, 4, 4, 0, 0, 2, 4, 3, 1, 2,\n",
       "         3, 2, 3, 2, 0, 3, 3, 4, 4, 3, 3, 3, 2, 2, 2, 2, 0, 2, 2, 2, 3, 4, 3, 1,\n",
       "         2, 3, 3, 4, 4, 2, 4, 2, 2, 4, 1, 3, 4, 1, 3, 3, 2, 4, 2, 1, 2, 4, 3, 4,\n",
       "         2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 3, 4, 2, 0, 3, 2, 1, 1, 3, 2, 2, 2, 3, 0,\n",
       "         1, 3, 4, 2, 4, 0, 1, 1, 2, 3, 3, 3, 0, 0, 3, 2, 4, 3, 1, 3, 4, 2, 2]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2HZc5ZYRV28"
   },
   "source": [
    "# Freeze BERT Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "wHZ0MC00RQA_"
   },
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7ahGBUWRi3X"
   },
   "source": [
    "# Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "b3iEtGyYRd0A"
   },
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = bert      \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512)      \n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "cBAJJVuJRliv"
   },
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "taXS0IilRn9J"
   },
   "outputs": [],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9CDpoMQR_rK"
   },
   "source": [
    "# Find Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "izY5xH5eR7Ur",
    "outputId": "4682d190-bf40-4824-89af-91983ae6b174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.39444444 1.43666667 0.63382353 0.70081301 1.13421053]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_wts = compute_class_weight(class_weight='balanced', \n",
    "                                 classes=np.unique(train_labels), \n",
    "                                 y=train_labels)\n",
    "# class_wts = dict(zip(np.unique(train_labels), class_wts))\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "r1WvfY2vSGKi"
   },
   "outputs": [],
   "source": [
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "My4CA0qaShLq"
   },
   "source": [
    "# Fine-Tune BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "rskLk8R_SahS"
   },
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch]\n",
    " \n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "yGXovFDlSxB5"
   },
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "  print(\"\\nEvaluating...\")\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "    # Progress update every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      \n",
    "      # Calculate elapsed time in minutes.\n",
    "      elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "      # Report progress.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "\n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KZEgxRRTLXG"
   },
   "source": [
    "# Start Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "k1USGTntS3TS",
    "outputId": "6c03e17f-476c-4741-eae5-c5722cb5d413"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4191/2583630083.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4191/2212538583.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# get model predictions for the current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# compute the loss between actual and predicted values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/exp-Env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4191/886072462.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#pass the inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yrhUc9kTI5a"
   },
   "source": [
    "# Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "OacxUyizS8d1",
    "outputId": "c8b951c2-1f74-4a13-db65-8acd077995e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4SVftkkTZXA"
   },
   "source": [
    "# Get Predictions for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZl0SZmFTRQA"
   },
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "  preds = model(test_seq.to(device), test_mask.to(device))\n",
    "  preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "Ms1ObHZxTYSI",
    "outputId": "47d01595-e519-4a58-8f2e-75596ea1512d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       724\n",
      "           1       0.88      0.92      0.90       112\n",
      "\n",
      "    accuracy                           0.97       836\n",
      "   macro avg       0.93      0.95      0.94       836\n",
      "weighted avg       0.97      0.97      0.97       836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "YqzLS7rHTp4T",
    "outputId": "d3abc432-5ad0-41e5-cfc2-d1d1192f5672"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>710</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1\n",
       "row_0          \n",
       "0      710   14\n",
       "1        9  103"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.crosstab(test_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpX1uTwjUPY6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Fine-Tuning BERT for Spam Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e580433bec2453da54c0ce9ee027401": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_73fc7587f1bb49df8a0fc87ecfac7f3c",
       "IPY_MODEL_4da1c15300b2468ab1a7e2df800ed39b"
      ],
      "layout": "IPY_MODEL_bdfd7634b8bf42aa8794ada8d9e47173"
     }
    },
    "3bb6b624b4ce4be788c38cb8d1936177": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47862cd626cf46619a5cc505fde02276": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49dd79a9a65044ba8345deb250ce4b24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4d56a47453914de3be15d7a515e5b210": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4da1c15300b2468ab1a7e2df800ed39b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88214abee8b9462f86369072d858ae9f",
      "placeholder": "​",
      "style": "IPY_MODEL_ed9f97f9d12a49aa939b7595ad3cb27c",
      "value": " 440M/440M [00:11&lt;00:00, 37.5MB/s]"
     }
    },
    "58cd585c531444a5b8613c2d85bab022": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59bae99ad63d4a3a8b8d622d95f7ad07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47862cd626cf46619a5cc505fde02276",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_49dd79a9a65044ba8345deb250ce4b24",
      "value": 433
     }
    },
    "645d520e8a1c4f1fa202c6c68c5ce6af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6831c2b733d74b31a41cb6eb971a25d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "689e66a8dff249449b5f0f5bbfffa037": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d2355752eb74f348596a380d2347b73",
      "placeholder": "​",
      "style": "IPY_MODEL_cb5f7a2a5bcb47649703cc633f2fb685",
      "value": " 433/433 [00:00&lt;00:00, 1.98kB/s]"
     }
    },
    "6d2355752eb74f348596a380d2347b73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73fc7587f1bb49df8a0fc87ecfac7f3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bb6b624b4ce4be788c38cb8d1936177",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_645d520e8a1c4f1fa202c6c68c5ce6af",
      "value": 440473133
     }
    },
    "88214abee8b9462f86369072d858ae9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cf06dad410440f78c50e3527e858905": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6831c2b733d74b31a41cb6eb971a25d7",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4d56a47453914de3be15d7a515e5b210",
      "value": 231508
     }
    },
    "94264f36ceb64d3881fed952bf579072": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "983fea7c2dc74dfaba7aa60147af85d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_59bae99ad63d4a3a8b8d622d95f7ad07",
       "IPY_MODEL_689e66a8dff249449b5f0f5bbfffa037"
      ],
      "layout": "IPY_MODEL_ccf5f7e5cc10493ca9c44b14fdec31dc"
     }
    },
    "b4bef5a685954e238b52c43eefe4c9e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8cf06dad410440f78c50e3527e858905",
       "IPY_MODEL_edf0e4c1ae214a66abb717b20e3bffad"
      ],
      "layout": "IPY_MODEL_94264f36ceb64d3881fed952bf579072"
     }
    },
    "b6423c858927455e8cbc5a953273466a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdfd7634b8bf42aa8794ada8d9e47173": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb5f7a2a5bcb47649703cc633f2fb685": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ccf5f7e5cc10493ca9c44b14fdec31dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed9f97f9d12a49aa939b7595ad3cb27c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "edf0e4c1ae214a66abb717b20e3bffad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6423c858927455e8cbc5a953273466a",
      "placeholder": "​",
      "style": "IPY_MODEL_58cd585c531444a5b8613c2d85bab022",
      "value": " 232k/232k [00:39&lt;00:00, 5.82kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
