{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d79b8d3c",
   "metadata": {},
   "source": [
    "# https://tsmatz.wordpress.com/2022/11/25/huggingface-japanese-summarization/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4efbfbb",
   "metadata": {},
   "source": [
    "## XL-Sum Japanese dataset in Hugging Face, which is the annotated article-summary pairs in BBC news corpus.\n",
    "## This dataset has around 7000 samples for training in Japanese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9096eec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab52117f7a534b72b437a909c7d2f6df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/13.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc66cc7590248c7b8385b016626cbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f49a26a524644cf8c0617aa24e69ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2774a04f191545b3ade69d8a15b225ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'url', 'title', 'summary', 'text'],\n",
       "        num_rows: 8102\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'url', 'title', 'summary', 'text'],\n",
       "        num_rows: 1012\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'url', 'title', 'summary', 'text'],\n",
       "        num_rows: 1012\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"csebuetnlp/xlsum\", name=\"bengali\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d665f459",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'news-54690291',\n",
       " 'url': 'https://www.bbc.com/bengali/news-54690291',\n",
       " 'title': \"দুর্গাপূজার সময়ে যেভাবে শোক পালন করেন 'মহিষাসুরের বংশধরেরা'\",\n",
       " 'summary': 'হিন্দু বাঙালীরা যে সময়ে তাদের সবথেকে বড় উৎসব দুর্গাপূজা উদযাপন করেন, সেই সময়েই শোক পালন করেন অসুর বংশীয় আদিবাসীরা।',\n",
       " 'text': 'দুর্গাপুজায় মহিষাসুর বধ্যে মধ্য দিয়ে অশুভর ওপর শুভর বিজয় দেখানো হয়। কিন্তু সেটা বিজয়ীর লেখা ইতিহাস বলেই গবেষকরা এখন বলছেন। তাদের লোককথা অনুযায়ী, আর্যদের দেবী দুর্গা এই সময়েই তাদের রাজা মহিষাসুরকে ছলনার মাধ্যমে হত্যা করেছিলেন। রাজাকে হারানোর শোক হাজার হাজার বছর ধরেও ভুলতে পারেননি আদিবাসী সমাজ। \\'অসুর\\' ভারতের একটি বিশেষ আদিবাসী উপজাতি। পশ্চিমবঙ্গ, ঝাড়খণ্ড আর বিহার - এই তিন রাজ্যের সরকারি তপশিলী উপজাতিদের তালিকার একেবারে প্রথম নামটিই হল অসুর। তবে এখন \\'অসুর\\' ছাড়া অন্য আদিবাসী সমাজও মহিষাসুর স্মরণ অনুষ্ঠানে অংশ নিচ্ছেন। পশ্চিমবঙ্গ, ঝাড়খণ্ড, ছত্তিশগড়ের আদিবাসী অধ্যুষিত এলাকাগুলিতে \\'মহান অসুর সম্রাট হুদুড় দুর্গা স্মরণ সভা\\'র আয়োজন প্রতিবছরই বাড়ছে বলে জানাচ্ছেন আদিবাসী সমাজ-গবেষকরা। \"২০১১ সালে গোটা পশ্চিমবঙ্গে ২০০-র কিছু বেশি এরকম স্মরণসভা হয়েছিল, ২০১৮ সালে সংখ্যাটা বেড়ে দাঁড়ায় ৭০০-র কিছু বেশি,\" বলছিলেন মহিষাসুর তথা ভারতের আদিবাসীদের উৎস সন্ধানে এক নির্মীয়মাণ তথ্যচিত্রের পরিচালক সুমিত চৌধুরী। মহিষাসুরের স্মরণে পূজা। আরও পড়তে পারেন: রামকে নিয়ে রসিকতা: অধ্যাপকের বিরুদ্ধে মামলা অযোধ্যা নেপালে, রাম নেপালি রাজপুত্র: নেপালের প্রধানমন্ত্রী যখন হিন্দু রীতিতে বিয়ে হলো মসজিদের ভেতরে আর এবছর পশ্চিমবঙ্গের শুধু তিনটি জেলা - মালদা, উত্তর দিনাজপুর এবং দক্ষিণ দিনাজপুরেই সাড়ে ৩৫০০ জায়গায় এই স্মরণ সভা হয়েছে বলে বিবিসিকে জানিয়েছেন আদিবাসীদের সামাজিক সংগঠন মাঝি পারগানা গাঁওতার নেতা চরন বেসরা। মহিষাসুরের নাম হুদুড় দুর্গা কেন হিন্দুদের বিশ্বাস মতে, তাদের দেবী দুর্গা মহিষাসুরকে বধ করেছিলেন। আবার আদিবাসী সমাজ মনে করে, দুর্গা আসলে তাদের \\'সম্রাট মহিষাসুর\\'-এর নাম, যেখানে তিনি পরিচিত হুদুড় দুর্গা বলে। গবেষক শরদিন্দু উদ্দীপনের ব্যাখ্যা, \"হুদুড় শব্দটার অর্থ হল ঝঞ্ঝা, বিদ্যুৎ বা বজ্রের ধ্বনি। এক্ষেত্রে মহিষাসুরের প্রভাব আর শক্তি ছিল বজ্রের মতো। আর দুর্গা শব্দটা দুর্গের রক্ষক অর্থে ব্যবহৃত। এটা পুংলিঙ্গ। প্রবল শক্তিশালী এক দুর্গের রক্ষক, অর্থাৎ রাজাই ছিলেন মহিষাসুর বা হুদুড় দুর্গা।\" বুন্দেলখণ্ডে এই মন্দিরে মহিষাসুরের পূজা হয় থাকে। \"তিনি ছিলেন অত্যন্ত বলশালী এবং প্রজাবৎসল এক রাজা। আদিবাসীদের প্রচলিত লোকগাথা অনুযায়ী এক গৌরবর্ণা নারীকে দিয়ে তাদের রাজাকে হত্যা করা হয়েছিল।\" \"এক গৌরবর্ণা নারীই যে মহিষাসুরকে বধ করেছিলেন, তা হিন্দু পুরাণেও আছে। দেবী দুর্গার যে প্রতিমা গড়া হয়, সেখানে দুর্গা গৌরবর্ণা, টিকলো নাক, যেগুলি আর্যদের শারীরিক বৈশিষ্ট্য। দুর্গার আরেক নাম সেজন্যই গৌরী। অন্যদিকে মহিষাসুরের যে মূর্তি গড়া হয় দুর্গাপূজায়, সেখান তার গায়ের রঙ কালো, কোঁকড়ানো চুল, পুরু ঠোঁট। এগুলো সবই অনার্যদের বৈশিষ্ট্য,\" ব্যাখ্যা তথ্যচিত্র নির্মাতা সুমিত চৌধুরীর। মি. উদ্দীপন আরও বলছিলেন যে আর্যরা ভারতে আসার পরে তারা কোনোভাবেই মহিষাসুরকে পরাজিত করতে পারছিল না। তাই তারা একটা কৌশল নেন, যাতে এক নারীকে তারা ব্যবহার করেন মহিষাসুরকে বধ করার জন্য। মহিষাসুর বধের দুই বিপরীত কাহিনী মহিষাসুরকে স্মরণ করছে আদিবাসী সম্প্রদায়। হিন্দু পুরাণে যেমন মহিষাসুর আর দেবী দুর্গার যুদ্ধের কাহিনী আছে, আদিবাসী লোকগাথাতেও সেই কাহিনী রয়েছে, কিন্তু দুটি কাহিনীর দৃষ্টিভঙ্গি সম্পূর্ণ বিপরীত। \"রাজা মহিষাসুরের সময়ে নারীদের অত্যন্ত সম্মান দেওয়া হত। এবং এরকম একজন রাজা কোনও নারীর সঙ্গে যুদ্ধে লিপ্ত হবেন না, বা তার বিরুদ্ধে অস্ত্র ধরবেন না, এরকমটাই ধারণা ছিল আর্যদের। তাই তারা দুর্গাকে এই কাজে ব্যবহার করেছিলেন বলেই আদিবাসী সমাজ মনে করে,\" বলছিলেন শরদিন্দু উদ্দীপন। আর হিন্দুদের পুরাণে মহিষাসুরকে একজন \\'ভিলেন\\' হিসাবে উপস্থাপন করা হয়। মহিষাসুরকে সাধারণত দানব হিসেবে তুলে ধরা হলেও এবারের দুর্গাপূজায় তাকে করোনাভাইরাস হিসেবে দেখানো হয়েছে। অসুর এবং অন্যান্যা আদিবাসী সম্প্রদায় এর প্রতিবাদ জানিয়েছেন। উনবিংশ শতকে প্রথম পৌরাণিক কাহিনীগুলির বিশ্লেষণ ও সমালোচনামূলক পর্যালোচনা করেছিলেন সামাজিক কর্মকর্তা ও ইতিহাসবিদ জ্যোতিরাও ফুলে। হিন্দুদের অবতার ও দেবদেবীদের আলোকে তিনি বিশ্লেষণ করেছিলেন ভারতের আদিবাসীদের লোকগাথা ও ইতিহাস। তারপরে মি. ফুলের কাজকে এগিয়ে নিয়ে যান ভারতের সংবিধান রচয়িতা বি. আর. আম্বেদকর। পুরাণ ও লোককথার ওপরে ভিত্তি করে তিনি আর্য ও অনার্যদের সংঘাতকে বিশ্লেষণ করেছিলেন। তার লেখাতেই প্রথম বলা হয় দানব, রাক্ষস, দৈত্য, কিন্নর, নাগ, যক্ষ এরা সব মিলে যে \\'অসুর\\' সম্প্রদায়, তারা আসলে মানুষই ছিলেন। তিনিই প্রথম এই অসুর সম্প্রদায়ের লড়াইয়ের ইতিহাস তুলে ধরেন। কীভাবে মহিষাসুরের জন্য শোক পালন করা হয় খাজুরাহোর মন্দিরে মহিষাসুরের মূর্তি। চিরাচরিত ভাবে দুর্গাপূজার সময়টাতেই মহিষাসুরের জন্য শোক পালন করে থাকে আদিবাসী সমাজ। কোথাও অরন্ধন পালন করা হয়, কোথাও জানলা-দরজা বন্ধ করে ঘরে বসে থাকেন আদিবাসীরা, যাতে দুর্গাপূজার যে উৎসব, সেই মন্ত্র বা ঢাকের শব্দ যাতে তাদের কানে না যায়। দুর্গাপূজার এই সময়ে তারা অশৌচ পালন করেন এবং ভুয়াং বাদ্যযন্ত্র নিয়ে নাচ হয়। দাসাই নাচ করেন তারা, যেখানে পুরুষরা নারী যোদ্ধার ছদ্মবেশ ধারণ করে কান্নার সুরে গান গেয়ে গ্রামে গ্রামে ঘোরেন। \"তাদের গানটা এরকম : \\'ওকার এদম ভুয়াং এদম জনম লেনা রে, ওকার এদম ভুয়াং এদম বছর লেনা রে\\'। তারা বিশ্বাস করে এই গানের মধ্যে যে প্রশ্ন আছে, তার উত্তর একমাত্র জানে হুদুড় দুর্গা। সে যদি এই গান শুনতে পায়, তাহলে জবাব দেবে এবং হুদুড় দুর্গাকে তারা চিহ্নিত করতে পারবে,\" বলছিলেন শরদিন্দু উদ্দীপন। \"তারা \\'বিন্দি বা মাকড়সাকে বলে, \\'ও বিন্দি, তোমরা কি কেউ আমার রাজাকে দেখেছ? আমাদের রাজাকে কোনও এক গৌরবর্ণা নারী চুরি করে নিয়ে গেছে\\',\" আদিবাসী সমাজের লোকগাথা বিশ্লেষণ করে বলছিলেন শরদিন্দু উদ্দীপন। মহিষাসুর স্মরণের ধরণ পাল্টাচ্ছে আদিবাসী সমাজের নেতা চরন বেসরা জানাচ্ছেন, এবছর করোনা মহামারির কারণে তাদের মূল কেন্দ্রীয় অনুষ্ঠানটি বাতিল করা হয়েছে। সেই অনুষ্ঠানটি হয় দুর্গাপূজা শেষ হওয়ার পরের দিন। কিন্তু গ্রামে গ্রামে মানুষ মহিষাসুর স্মরণ করছেন নিজেদের মতো করে। \"ষষ্ঠী, সপ্তমী থেকেই শুরু হয় শোক পালন। দাসাই, ভুয়াং এগুলো চলতে থাকে পাড়ায় পাড়ায়। আর দশমীর দিন হয় বড় অনুষ্ঠান। আমরা এগুলো করতে শুরু করেছি ২০১২ সাল থেকে। আর প্রতিবছরই সংখ্যাটা বাড়ছে। \"আমরা চেষ্টা করছি আর্য সভ্যতা-সংস্কৃতির বিপরীতে ভারতের আদি বাসিন্দাদের সংস্কৃতি পুণঃপ্রতিষ্ঠা করতে,\" বলছিলেন চরণ বেসরা। বছর দশেক আগে থেকে সংগঠিতভাবে মহিষাসুর স্মরণ অনুষ্ঠান করা হলেও আদিবাসী সমাজ কিন্তু হাজার হাজার বছর ধরে তাদের রাজার জন্য শোক ব্যক্ত করে আসছে। নতুন করে যেভাবে শোক পালন অনুষ্ঠানগুলো হচ্ছে, তার সঙ্গে চিরাচরিত প্রথায় শোক পালনের একটা ফারাক আছে বলে মনে করেন মহিষাসুর গবেষক প্রমোদ রঞ্জন। মি. রঞ্জন এখন আসাম বিশ্ববিদ্যালয়ে অধ্যাপনা করেন, কিন্তু তার বড় পরিচয় হল ভারতের নানা জায়গায় ঘুরে মহিষাসুর সম্বন্ধীয় ঐতিহাসিক প্রমাণ যোগাড় করেছেন তিনি। \"তফাৎটা হল যে চিরাচরিত প্রথায় যেভাবে শোক পালন হত, তার ভিত্তি ছিল লোকগাথা আর এখন যেটা হচ্ছে সেটা একটা ইতিবাচক সাংস্কৃতিক রাজনীতি। যেটা একদিকে মনুবাদী সংস্কৃতির বিরুদ্ধে আদিবাসী সমাজের রুখে দাঁড়ানোর প্রচেষ্টা অন্যদিকে তাদের নিজস্ব সংস্কৃতিকে তুলে ধরার প্রয়াস,\" বলছিলেন মি. রঞ্জন। মহিষাসুরের খোঁজে গবেষকদের মতে মহিষাসুর সংক্রান্ত যে লোকগাঁথা রয়েছে, তা প্রায় ৩০০০ বছর পুরনো, যখন আর্যরা ভারতবর্ষে আসেননি। এমন কি বুদ্ধেরও আগের যুগের ইতিহাস এটা। আর মহিষাসুর সম্বন্ধীয় লোকগাঁথা গোটা দক্ষিণ এশিয়াজুড়েই পাওয়া যায়। উত্তর ভারত থেকে শুরু করে দাক্ষিণাত্য, বর্তমানের নেপাল - বাংলাদেশেরও নানা জায়গায়। প্রমোদ রঞ্জনের কথায়, \"বিশ্লেষণ করলে দেখা যায় যে এই অসুর জাতির ইতিহাস আর্যদের পূর্ববর্তী যুগের ইতিহাস। আমরা যেমন মহিষাসুরকে খুঁজে পেয়েছি বর্তমান উত্তর প্রদেশের বুন্দেলখন্ডে, আবার এখনকার যে মহীশুর বা মাইসোর শহর, সেই অঞ্চলেও মহিষাসুরের অস্তিত্ব পাওয়া যায়। আবার খাজুরাহোর যে বিশ্বখ্যাত মন্দির, সেখানেও মহিষাসুরের মূর্তি পেয়েছি আমরা। অর্থাৎ শুধু যে লোকগাঁথায় মহিষাসুর আছেন, তা নয়। প্রত্নতাত্ত্বিক নিদর্শনও খুঁজে পেয়েছি আমরা।\" \\'অসুর\\' নামের যে জনজাতি, তারা ছাড়াও ভারতের আদিমতম আদিবাসী বলে পরিচিত ছত্তিশগড়ের গোন্ড সম্প্রদায়ের মধ্যেও মহিষাসুরের লোকগাঁথা ব্যাপকভাবে প্রচলিত বলে জানাচ্ছিলেন মি. রঞ্জন। দু\\'হাজার চৌদ্দ সালে তার কাছে কতগুলি ছবি আসে, যেগুলি ছিল উত্তরপ্রদেশের বুন্দেলখন্ড এলাকায় ছড়িয়ে ছিটিয়ে থাকা মহিষাসুরের কয়েকটি প্রত্ন নিদর্শনের ছবি। প্রমোদ রঞ্জন সেই সময়ে দিল্লির ফরোয়ার্ড প্রেস নামে একটি প্রকাশনা সংস্থা, যারা মূলত দলিত সম্প্রদায়ের সাহিত্য নিয়ে কাজ করে, সেটির ব্যবস্থাপনা পরিচালক ছিলেন। তার মধ্যে এমন একটি ছবি ছিল, যেটি ভারত সরকারের আর্কিওলজিকাল সার্ভের সংরক্ষিত একটি নিদর্শন, যার নাম মহিষাসুর স্মারক। প্রমোদ রঞ্জনের কথায়, \"শুধুমাত্র ওই কয়েকটি ছবি সম্বল করে আমি এবং আমার এক সহকর্মী ট্রেনে চেপে দিল্লি থেকে প্রায় ৬০০ কিলোমিটার দূরে মাহোবা রেল স্টেশনে নেমেছিলাম এক রাতে। স্টেশনের আশেপাশে অনেককে দেখিয়েছিলাম ছবিগুলো। কিন্তু কেউ বুঝতে পারেনি যে ওই জায়গাগুলো কোথায়।\" দিন দুয়েক পরে তারা খুঁজে পেয়েছিলেন মহিষাসুর স্মারক। \"একজন আমাদের পাঠায় কুলাপাহাড় নামের এক জায়গায়, কিন্তু সেখানেও কিছু পাইনি আমরা। অনেক খোঁজাখুঁজির পরে কুলাপাহাড় থেকে প্রায় ৭০ কিলোমিটার দূরে চাউকা নামের একটা জায়গার কথা বলে একজন। সেখানে পৌঁছিয়ে আমরা নিশ্চিত হলাম যে সঠিক জায়গায় এসেছি। পুরাতত্ত্ব বিভাগের একটি বোর্ড দেখতে পেলাম,\" বলছিলেন প্রমোদ রঞ্জন। ওই স্মারকটি ভারত সরকারের পুরাতত্ত্ব বিভাগ সংরক্ষণ করে রেখেছে। পরে মি. রঞ্জনের এক প্রশ্নের জবাবে পুরাতত্ত্ব বিভাগ জানায় যে ওই স্মারকটি একাদশ শতকের। দিন দুয়েক পরে মাহোবায় ফিরে এসে কাছাকাছি মহিষাসুরের আরও নিদর্শন খুঁজতে থাকেন তারা। গোখর পাহাড়ে আলাপ হওয়া এক সাধুর কাছে তাঁরা জানতে পারেন যে ওই অঞ্চলে মহিষাসুর ব্যাপকভাবে পূজিত হন। কোথাও ভৈঁসাসুর, কোথাও মাইকাসুর আবার কোথাও মহিষাসুর নামে তাঁর পুজা দেন দলিত শ্রেণীর যাদব আর পাল বংশীয় মানুষ। মহিষাসুরকে তাঁরা গরু, মোষের মতো গৃহপালিত পশুর রক্ষাকর্তা বলে মনে করেন। মি. রঞ্জন বলছেন, গ্রামগুলিতে মহিষাসুরের মন্দির থাকে না, তবে বাঁধানো চাতাল মতো একটা জায়গায় পূজা করেন স্থানীয় মানুষ। আবার খাজুরাহোর ওয়ার্ল্ড হেরিটেজ সাইটেও তিনি মহিষাসুরের মূর্তি দেখতে পেয়েছেন। গবেষক শরদিন্দু উদ্দীপন বলছিলেন, সম্রাট অশোকের আমলে মহিষাসুরকে বর্তমানের মহিশুর বা মাইসোর অঞ্চলটি শাসন করতে পাঠিয়েছিলেন তিনি। সব নিদর্শনগুলি দেখে প্রমোদ রঞ্জনের মত হল, \"মহিষাসুর নানা যুগেই ছড়িয়ে ছিলেন। তাই এটা সম্ভবত কোনও এক ব্যক্তি নন, এটা একটা উপাধি। যার পরম্পরা দক্ষিণ এশিয়ার নানা এলাকায় ছড়িয়ে আছে। যে পরম্পরা হাজার হাজার বছর ধরে বয়ে আসছেন আদিবাসীরা।\" বিবিসি বাংলায় অন্যান্য খবর: ইন্দো-প্যাসিফিকে চীনকে রুখতেই ভারত-আমেরিকার \\'দুই আর দুই\\' বিদেশি মদ রাখার দায়ে ইরফান সেলিমের কারাদণ্ড পর্নোগ্রাফি আসক্তি যেভাবে সব ধারণা বদলে দেয়'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f666c39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0ca057a47f4515b4e0d4dfe9ea3781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/82.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e800a86579be44f1b8d4a16205418e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/553 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e788b3123b34facb08cd9ba3b4f3545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547ef32d2b154ed1aa72498d02e397ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "C:\\Users\\iftek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "t5_tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "963c7afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e842a04cf37e46f990908436a8af44cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99af54a9953f4c9db563c59eefe52c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e901b74675644b6b7c94679fe5131b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_sample_data(data):\n",
    "  # Max token size is 14536 and 215 for inputs and labels, respectively.\n",
    "  # Here I restrict these token size.\n",
    "  input_feature = t5_tokenizer(data[\"text\"], truncation=True, max_length=1024)\n",
    "  label = t5_tokenizer(data[\"summary\"], truncation=True, max_length=128)\n",
    "  return {\n",
    "    \"input_ids\": input_feature[\"input_ids\"],\n",
    "    \"attention_mask\": input_feature[\"attention_mask\"],\n",
    "    \"labels\": label[\"input_ids\"],\n",
    "  }\n",
    "\n",
    "tokenized_ds = ds.map(\n",
    "  tokenize_sample_data,\n",
    "  remove_columns=[\"id\", \"url\", \"title\", \"summary\", \"text\"],\n",
    "  batched=True,\n",
    "  batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43f749f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 8102\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1012\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1012\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76699b7a",
   "metadata": {},
   "source": [
    "### Before fine-tuning, load pre-trained model and data collator.\n",
    "\n",
    "### In HuggingFace, several sizes of mT5 models are available, and here I’ll use small one (google/mt5-small) to fit to memory in my machine.\n",
    "### The name is “small”, but it’s still so large (over 1 GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a218f20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9591c562c204b68825573488388e11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83445ae09f0f41bfb44c33afb20cdb9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoConfig, AutoModelForSeq2SeqLM\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# see https://huggingface.co/docs/transformers/main_classes/configuration\n",
    "mt5_config = AutoConfig.from_pretrained(\n",
    "  \"google/mt5-small\",\n",
    "  max_length=128,\n",
    "  length_penalty=0.6,\n",
    "  no_repeat_ngram_size=2,\n",
    "  num_beams=15,\n",
    ")\n",
    "model = (AutoModelForSeq2SeqLM\n",
    "         .from_pretrained(\"google/mt5-small\", config=mt5_config)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fbe55e",
   "metadata": {},
   "source": [
    "### For the sequence-to-sequence (seq2seq) task, we need to not only stack the inputs for encoder, but also prepare for the decoder side. In seq2seq setup, a common technique called “teach forcing” will then be applied in decoder.\n",
    "### In Hugging Face, these tasks are not needed to be manually setup and the following DataCollatorForSeq2Seq will take care of all steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b7c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "  t5_tokenizer,\n",
    "  model=model,\n",
    "  return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132f6ab",
   "metadata": {},
   "source": [
    "### The idea of ROUGE is similar to BLEU, but it also measures how many of n-gram tokens in the reference text appears in the generated (predicted) text. (This is why the name of ROUGE includes “RO”, which means “Recall-Oriented”.)\n",
    "### There also exist variations, ROUGE-L and ROUGE-Lsum, which also counts the longest common substrings (LCS) in ROUGE metrics computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c09b4709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "# define function for custom tokenization\n",
    "def tokenize_sentence(arg):\n",
    "  encoded_arg = t5_tokenizer(arg)\n",
    "  return t5_tokenizer.convert_ids_to_tokens(encoded_arg.input_ids)\n",
    "\n",
    "# define function to get ROUGE scores with custom tokenization\n",
    "def metrics_func(eval_arg):\n",
    "  preds, labels = eval_arg\n",
    "  # Replace -100\n",
    "  labels = np.where(labels != -100, labels, t5_tokenizer.pad_token_id)\n",
    "  # Convert id tokens to text\n",
    "  text_preds = t5_tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "  text_labels = t5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "  # Insert a line break (\\n) in each sentence for ROUGE scoring\n",
    "  # (Note : Please change this code, when you perform on other languages except for Japanese)\n",
    "  text_preds = [(p if p.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else p + \"。\") for p in text_preds]\n",
    "  text_labels = [(l if l.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else l + \"。\") for l in text_labels]\n",
    "  sent_tokenizer_jp = RegexpTokenizer(u'[^!！?？。]*[!！?？。]')\n",
    "  text_preds = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(p))) for p in text_preds]\n",
    "  text_labels = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(l))) for l in text_labels]\n",
    "  # compute ROUGE score with custom tokenization\n",
    "  return rouge_metric.compute(\n",
    "    predictions=text_preds,\n",
    "    references=text_labels,\n",
    "    tokenizer=tokenize_sentence\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f010c7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "C:\\Users\\iftek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1421: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.11761273733876473,\n",
       " 'rouge2': 0.06261264940510224,\n",
       " 'rougeL': 0.11826839826839827,\n",
       " 'rougeLsum': 0.11761273733876473}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sample_dataloader = DataLoader(\n",
    "  tokenized_ds[\"test\"].with_format(\"torch\"),\n",
    "  collate_fn=data_collator,\n",
    "  batch_size=5)\n",
    "for batch in sample_dataloader:\n",
    "  with torch.no_grad():\n",
    "    preds = model.generate(\n",
    "      batch[\"input_ids\"].to(device),\n",
    "      num_beams=15,\n",
    "      num_return_sequences=1,\n",
    "      no_repeat_ngram_size=1,\n",
    "      remove_invalid_values=True,\n",
    "      max_length=128,\n",
    "    )\n",
    "  labels = batch[\"labels\"]\n",
    "  break\n",
    "\n",
    "metrics_func([preds, labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5931eb4",
   "metadata": {},
   "source": [
    "### In usual training evaluation, training loss and accuracy will be computed and evaluated, by comparing the generated logits with labels. However, as we saw above, we want to evaluate ROUGE score using the predicted tokens.\n",
    "### To simplify these sequence-to-sequence specific steps, here I use built-in Seq2SeqTrainingArguments and Seq2SeqTrainer classes, instead of usual TrainingArguments and Trainer.\n",
    "### By setting predict_with_generate=True as follows in this class, the predicted tokens will be generated by model.generate() and it will then be passed into evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f034dc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Seq2SeqTrainingArguments\n\u001b[1;32m----> 3\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mSeq2SeqTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmt5-summarize-Bengali\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43mlog_level\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43merror\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m  \u001b[49m\u001b[43mlr_scheduler_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m  \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m  \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madafactor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m  \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m  \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m  \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m  \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m  \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m  \u001b[49m\u001b[43meval_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m  \u001b[49m\u001b[43mpredict_with_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m  \u001b[49m\u001b[43mgeneration_max_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m  \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m  \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m  \u001b[49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<string>:120\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, include_tokens_per_second, sortish_sampler, predict_with_generate, generation_max_length, generation_num_beams, generation_config)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:1436\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1430\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(version\u001b[38;5;241m.\u001b[39mparse(torch\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mbase_version) \u001b[38;5;241m==\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16:\n\u001b[0;32m   1431\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1435\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[1;32m-> 1436\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1437\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1438\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (get_xla_device_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1440\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16_full_eval)\n\u001b[0;32m   1441\u001b[0m ):\n\u001b[0;32m   1442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1443\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1444\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (`--fp16_full_eval`) can only be used on CUDA or NPU devices or certain XPU devices (with IPEX).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1445\u001b[0m     )\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1448\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1449\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16_full_eval)\n\u001b[0;32m   1457\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:1901\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1898\u001b[0m \u001b[38;5;124;03mThe device used by this process.\u001b[39;00m\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1900\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m-> 1901\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_devices\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:54\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, obj, objtype)\u001b[0m\n\u001b[0;32m     52\u001b[0m cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:1801\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available(min_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.20.1\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1801\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   1802\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1803\u001b[0m         )\n\u001b[0;32m   1804\u001b[0m     AcceleratorState\u001b[38;5;241m.\u001b[39m_reset_state(reset_partial_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "  output_dir = \"mt5-summarize-Bengali\",\n",
    "  log_level = \"error\",\n",
    "  num_train_epochs = 10,\n",
    "  learning_rate = 5e-4,\n",
    "  lr_scheduler_type = \"linear\",\n",
    "  warmup_steps = 90,\n",
    "  optim = \"adafactor\",\n",
    "  weight_decay = 0.01,\n",
    "  per_device_train_batch_size = 2,\n",
    "  per_device_eval_batch_size = 1,\n",
    "  gradient_accumulation_steps = 16,\n",
    "  evaluation_strategy = \"steps\",\n",
    "  eval_steps = 100,\n",
    "  predict_with_generate=True,\n",
    "  generation_max_length = 128,\n",
    "  save_steps = 500,\n",
    "  logging_steps = 10,\n",
    "  push_to_hub = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03056f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef0593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
