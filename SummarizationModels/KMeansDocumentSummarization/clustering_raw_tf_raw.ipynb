{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    " from collections import Counter, defaultdict\n",
    " from scipy.sparse import csr_matrix\n",
    " import math\n",
    " from sklearn.preprocessing import normalize\n",
    " import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import MeCab\n",
    "tagger = MeCab.Tagger(\"-Owakati\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/ifte/Downloads/chat_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_cleaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>明日の天気</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>今日の天気</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ディズニー</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>今日の天気</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>今日の天気</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_cleaning\n",
       "0          明日の天気\n",
       "1          今日の天気\n",
       "2          ディズニー\n",
       "3          今日の天気\n",
       "4          今日の天気"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = []\n",
    "for items in df.query_cleaning.values:\n",
    "    collector.append(tagger.parse(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pd.DataFrame(zip(collector, df.query_cleaning.values.tolist()), columns=['pro', 'raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'明日の天気'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen['raw'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pro</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>明日 の 天気 \\n</td>\n",
       "      <td>明日の天気</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>今日 の 天気 \\n</td>\n",
       "      <td>今日の天気</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ディズニー \\n</td>\n",
       "      <td>ディズニー</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>今日 の 天気 \\n</td>\n",
       "      <td>今日の天気</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>今日 の 天気 \\n</td>\n",
       "      <td>今日の天気</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pro    raw\n",
       "0  明日 の 天気 \\n  明日の天気\n",
       "1  今日 の 天気 \\n  今日の天気\n",
       "2    ディズニー \\n  ディズニー\n",
       "3  今日 の 天気 \\n  今日の天気\n",
       "4  今日 の 天気 \\n  今日の天気"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    " def IDF(corpus, unique_words):\n",
    "   idf_dict={}\n",
    "   N=len(corpus)\n",
    "   for i in unique_words:\n",
    "     count=0\n",
    "     for sen in corpus:\n",
    "       if i in sen.split():\n",
    "         count=count+1\n",
    "       idf_dict[i]=(math.log((1+N)/(count+1)))+1\n",
    "   return idf_dict \n",
    "\n",
    " def fit(whole_data):\n",
    "    unique_words = set()\n",
    "    if isinstance(whole_data, (list,)):\n",
    "      for x in whole_data:\n",
    "        for y in x.split():\n",
    "          if len(y)<2:\n",
    "            continue\n",
    "          unique_words.add(y)\n",
    "      unique_words = sorted(list(unique_words))\n",
    "      vocab = {j:i for i,j in enumerate(unique_words)}\n",
    "      Idf_values_of_all_unique_words=IDF(whole_data,unique_words)\n",
    "    return vocab, Idf_values_of_all_unique_words\n",
    "\n",
    "def transform(dataset,vocabulary,idf_values):\n",
    "     sparse_matrix= csr_matrix( (len(dataset), len(vocabulary)), dtype=np.float64)\n",
    "     for row  in range(0,len(dataset)):\n",
    "       number_of_words_in_sentence=Counter(dataset[row].split())\n",
    "       for word in dataset[row].split():\n",
    "           if word in  list(vocabulary.keys()):\n",
    "               tf_idf_value=(number_of_words_in_sentence[word]/len(dataset[row].split()))*(idf_values[word])\n",
    "               sparse_matrix[row,vocabulary[word]]=tf_idf_value     \n",
    "#      output =normalize(sparse_matrix, norm='l2', axis=1, copy=True, return_norm=False)\n",
    "     return normalize(sparse_matrix, norm='l2', axis=1, copy=True, return_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = gen.pro.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ifte/environments/experiment_env/lib/python3.6/site-packages/scipy/sparse/_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    }
   ],
   "source": [
    "Vocabulary, idf_of_vocabulary=fit(corpus)\n",
    "final_output=transform(corpus,Vocabulary,idf_of_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5130"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = SampleSegregate(k=int(len(gen)/25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ifte/environments/experiment_env/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/ifte/environments/experiment_env/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/ifte/environments/experiment_env/lib/python3.6/site-packages/ipykernel_launcher.py:42: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/ifte/environments/experiment_env/lib/python3.6/site-packages/ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "out = s.fit(final_output.toarray(), gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class', 'raw', 'pro'], dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>raw</th>\n",
       "      <th>pro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>明日の天気</td>\n",
       "      <td>明日 の 天気 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0</td>\n",
       "      <td>明日の天気</td>\n",
       "      <td>明日 の 天気 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0</td>\n",
       "      <td>明日の天気</td>\n",
       "      <td>明日 の 天気 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>0</td>\n",
       "      <td>明日の天気</td>\n",
       "      <td>明日 の 天気 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0</td>\n",
       "      <td>明日の天気</td>\n",
       "      <td>明日 の 天気 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>202</td>\n",
       "      <td>時間</td>\n",
       "      <td>時間 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4315</th>\n",
       "      <td>202</td>\n",
       "      <td>時間 返せる</td>\n",
       "      <td>時間 返せる \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>204</td>\n",
       "      <td>時間 説明</td>\n",
       "      <td>時間 説明 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>204</td>\n",
       "      <td>時間 説明</td>\n",
       "      <td>時間 説明 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>204</td>\n",
       "      <td>時間 説明</td>\n",
       "      <td>時間 説明 \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5130 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class     raw         pro\n",
       "0         0   明日の天気  明日 の 天気 \\n\n",
       "870       0   明日の天気  明日 の 天気 \\n\n",
       "867       0   明日の天気  明日 の 天気 \\n\n",
       "1329      0   明日の天気  明日 の 天気 \\n\n",
       "254       0   明日の天気  明日 の 天気 \\n\n",
       "...     ...     ...         ...\n",
       "203     202      時間       時間 \\n\n",
       "4315    202  時間 返せる   時間 返せる \\n\n",
       "216     204   時間 説明    時間 説明 \\n\n",
       "204     204   時間 説明    時間 説明 \\n\n",
       "205     204   時間 説明    時間 説明 \\n\n",
       "\n",
       "[5130 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.sort_values(by='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import MeCab\n",
    "import math\n",
    "import re\n",
    "\n",
    "tagger = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "\n",
    "def inv_dict_gen(corpus, unique_words):\n",
    "    inv_dict = {}\n",
    "    for i in unique_words:\n",
    "        count = 0\n",
    "        for sen in corpus:\n",
    "            if i in sen.split():\n",
    "                count = count + 1\n",
    "            inv_dict[i] = (math.log((1 + len(corpus)) / (count + 1))) + 1\n",
    "    return inv_dict\n",
    "\n",
    "\n",
    "def train_data(dataset):\n",
    "    unique_words = set()\n",
    "    for x in dataset:\n",
    "        for y in x.split():\n",
    "            if len(y) < 3 and bool(re.compile('[a-z]').match(y)):\n",
    "                continue\n",
    "            unique_words.add(y)\n",
    "\n",
    "    unique_words = sorted(list(unique_words))\n",
    "    vocabulary = {j: i for i, j in enumerate(unique_words)}\n",
    "    inv_values = inv_dict_gen(dataset, unique_words)\n",
    "    sparse_matrix = csr_matrix((len(dataset), len(vocabulary)), dtype=np.float64)\n",
    "\n",
    "    for row in range(0, len(dataset)):\n",
    "        words = Counter(dataset[row].split())\n",
    "        for word in dataset[row].split():\n",
    "            if word in list(vocabulary.keys()):\n",
    "                sparse_matrix[row, vocabulary[word]] = (words[word] / len(dataset[row].split())) * (inv_values[word])\n",
    "\n",
    "    return normalize(sparse_matrix, norm='l2', axis=1, copy=True, return_norm=False).toarray()\n",
    "\n",
    "\n",
    "# Segregate the samples\n",
    "class SampleSegregate:\n",
    "    def __init__(self, k=3, tolerance=0.0001, max_iterations=500):\n",
    "        self.classes = {}\n",
    "        self.centroids = {}\n",
    "        self.k = k\n",
    "        self.tolerance = tolerance\n",
    "        self.max_iterations = max_iterations\n",
    "\n",
    "    def fit_matrix(self, data, dataframe):\n",
    "        saver = {}\n",
    "        self.centroids = {}\n",
    "        for i in range(self.k):\n",
    "            self.centroids[i] = data[i]\n",
    "\n",
    "        for i in range(self.max_iterations):\n",
    "            self.classes = {}\n",
    "            for i in range(self.k):\n",
    "                self.classes[i] = []\n",
    "\n",
    "            # distance [point <=> cluster]\n",
    "            c = 0\n",
    "            saver = defaultdict(list)\n",
    "            for features in data:\n",
    "                distances = [np.linalg.norm(features - self.centroids[centroid]) for centroid in self.centroids]\n",
    "                classification = distances.index(min(distances))\n",
    "                self.classes[classification].append(features)\n",
    "                saver['cluster'].append(classification)\n",
    "                saver['text'].append(dataframe['raw'].iloc[c])\n",
    "                c += 1\n",
    "\n",
    "            previous = dict(self.centroids)\n",
    "            # average cluster data points re-calculate centroids\n",
    "            for classification in self.classes:\n",
    "                self.centroids[classification] = np.average(self.classes[classification], axis=0)\n",
    "\n",
    "            optimal = True\n",
    "            for centroid in self.centroids:\n",
    "                original_centroid = previous[centroid]\n",
    "                curr = self.centroids[centroid]\n",
    "                if np.sum((curr - original_centroid) / original_centroid * 100.0) > self.tolerance:\n",
    "                    optimal = False\n",
    "\n",
    "            # break if optimal\n",
    "            if optimal:\n",
    "                break\n",
    "\n",
    "        return pd.DataFrame(saver)\n",
    "\n",
    "    def predict(self, data):\n",
    "        distances = [np.linalg.norm(data - self.centroids[centroid]) for centroid in self.centroids]\n",
    "        classification = distances.index(min(distances))\n",
    "        return classification\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ifte/environments/experiment_env/lib/python3.6/site-packages/scipy/sparse/_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/ifte/Downloads/chat_history.csv')\n",
    "\n",
    "collector = []\n",
    "for items in df.query_cleaning.values:\n",
    "    collector.append(tagger.parse(items))\n",
    "\n",
    "gen = pd.DataFrame(zip(collector, df.query_cleaning.values.tolist()), columns=['pro', 'raw'])\n",
    "matrix = train_data(gen.pro.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = SampleSegregate(k=10)\n",
    "# s.fit_matrix(matrix, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_score_max = -1\n",
    "for n_clusters in range(4, 30):\n",
    "    labels = s.predict(matrix[:100])\n",
    "    sil_score = silhouette_score(matrix[:100], labels)\n",
    "    print(\"The average silhouette score for %i clusters is %0.2f\" % (n_clusters, sil_score))\n",
    "    if sil_score > sil_score_max:\n",
    "        sil_score_max = sil_score\n",
    "        best_n_clusters = n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "kMeansCluster = KMeans(n_clusters=20)\n",
    "kMeansCluster.fit(matrix)\n",
    "clusters = kMeansCluster.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for number of cluster(s) 3: 0.06252950918587859\n",
      "Silhouette score for number of cluster(s) 4: 0.07808636490420136\n",
      "Silhouette score for number of cluster(s) 5: 0.06521017681591557\n",
      "Silhouette score for number of cluster(s) 6: 0.08817938896485673\n",
      "Silhouette score for number of cluster(s) 7: 0.08652936533682594\n",
      "Silhouette score for number of cluster(s) 8: 0.10476718351939034\n",
      "Silhouette score for number of cluster(s) 9: 0.11170184334180273\n",
      "Silhouette score for number of cluster(s) 10: 0.12142940097261096\n",
      "Silhouette score for number of cluster(s) 11: 0.1369359522332204\n",
      "Silhouette score for number of cluster(s) 12: 0.13714500546961503\n",
      "Silhouette score for number of cluster(s) 13: 0.14400596793182407\n",
      "Silhouette score for number of cluster(s) 14: 0.14936710468203\n",
      "Silhouette score for number of cluster(s) 15: 0.1646809550175829\n",
      "Silhouette score for number of cluster(s) 16: 0.1718625543645005\n",
      "Silhouette score for number of cluster(s) 17: 0.16298560760663003\n",
      "Silhouette score for number of cluster(s) 18: 0.17999232785341146\n",
      "Silhouette score for number of cluster(s) 19: 0.1847193710822066\n"
     ]
    }
   ],
   "source": [
    "km_silhouette = []\n",
    "for i in range(3,20):\n",
    "    km = KMeans(n_clusters=i, random_state=0).fit(matrix)\n",
    "    preds = km.predict(matrix)\n",
    "    \n",
    "    silhouette = silhouette_score(matrix, preds)\n",
    "    km_silhouette.append(silhouette)\n",
    "    print(\"Silhouette score for number of cluster(s) {}: {}\".format(i,silhouette))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ifte/environments/experiment_env/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/ifte/environments/experiment_env/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/ifte/environments/experiment_env/lib/python3.6/site-packages/ipykernel_launcher.py:87: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/ifte/environments/experiment_env/lib/python3.6/site-packages/ipykernel_launcher.py:87: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "result = s.fit_matrix(matrix, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 7])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.cluster.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.text = result.text.apply(lambda x: x+' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>明日の天気</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>今日の天気</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ディズニー</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>今日の天気</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>今日の天気</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster   text\n",
       "0        0  明日の天気\n",
       "1        1  今日の天気\n",
       "2        2  ディズニー\n",
       "3        1  今日の天気\n",
       "4        1  今日の天気"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      text\n",
      "cluster                                                   \n",
      "0        明日の天気記載 ヘルプ 使い方学習 ヘルプami e学習 url なん学習 ファイル追加 学...\n",
      "1        今日の天気今日の天気今日の天気今日の天気今日の天気今日の天気今日の天気今日の天気今日の天気 ...\n",
      "2        ディズニーios リモート 操作回答 分類保険料 控除足りる ない た足りる ない た足りる...\n",
      "7        シナリオ 登録シナリオ 登録シナリオ 登録シナリオ 登録シナリオ 登録シナリオ 登録シナリオ...\n"
     ]
    }
   ],
   "source": [
    "grouped = result.groupby('cluster', sort=False).sum()\n",
    "grouped.sort_index(ascending=False)\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text\n",
       "        count\n",
       "cluster      \n",
       "0        4748\n",
       "1         155\n",
       "2          90\n",
       "7         137"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.groupby('cluster').agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class            text [0         5           明日の天気] [1         5           今日の天気] [2         5           ディズニー] [3         5           今日の天気] [4         5           今日の天気] [...     ...             ...] [5125      5          スマホワーク] [5126      5  申し込む お ある "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/ifte/Downloads/clustered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('class').agg(['count'])\n",
    "# sentence_count.columns = ['class', 'Text']\n",
    "# sentence_count = sentence_count.sort_values(by='Text', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=df.columns[0], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.groupby('cluster').agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_count = df.set_index([\"class\", \"text\"]).count(level=\"class\")\n",
    "\n",
    "sentence_count.columns = ['Text']\n",
    "\n",
    "sentence_count = sentence_count.reset_index()\n",
    "\n",
    "sentence_count = sentence_count.sort_values(by='Text', ascending=False)\n",
    "\n",
    "sentence_count = sentence_count.reset_index()\n",
    "\n",
    "sentence_count.columns = ['cluster', 'Text']\n",
    "\n",
    "sentence_count = sentence_count.sort_values(by='Text', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['class'] == 1)].text.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_count = df.set_index([\"class\", \"text\"]).count(level=\"class\")\n",
    "sentence_count = sentence_count.reset_index()\n",
    "sentence_count.columns = ['cluster', 'Text']\n",
    "sentence_count.sort_values(by='Text', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('class')[['text']].agg(['count'])\n",
    "grouped = grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['count'], dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.columns = ['class', 'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  text\n",
       "        count\n",
       "0     0    87\n",
       "1     1   100\n",
       "2     2   170\n",
       "3     3   322\n",
       "4     4    65"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
