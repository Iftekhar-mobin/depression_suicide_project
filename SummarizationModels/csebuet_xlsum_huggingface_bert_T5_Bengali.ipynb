{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d79b8d3c",
   "metadata": {},
   "source": [
    "# https://tsmatz.wordpress.com/2022/11/25/huggingface-japanese-summarization/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4efbfbb",
   "metadata": {},
   "source": [
    "## XL-Sum Japanese dataset in Hugging Face, which is the annotated article-summary pairs in BBC news corpus.\n",
    "## This dataset has around 7000 samples for training in Japanese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9096eec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'url', 'title', 'summary', 'text'],\n",
       "        num_rows: 8102\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'url', 'title', 'summary', 'text'],\n",
       "        num_rows: 1012\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'url', 'title', 'summary', 'text'],\n",
       "        num_rows: 1012\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"csebuetnlp/xlsum\", name=\"bengali\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a5b9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds[\"train\"].select(range(10)).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b80ffeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Bengali_summarization.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db60294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e31bf183",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Bengali_summarization.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d28650c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news-54690291</td>\n",
       "      <td>https://www.bbc.com/bengali/news-54690291</td>\n",
       "      <td>দুর্গাপূজার সময়ে যেভাবে শোক পালন করেন 'মহিষাস...</td>\n",
       "      <td>হিন্দু বাঙালীরা যে সময়ে তাদের সবথেকে বড় উৎসব...</td>\n",
       "      <td>দুর্গাপুজায় মহিষাসুর বধ্যে মধ্য দিয়ে অশুভর ও...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news-50797621</td>\n",
       "      <td>https://www.bbc.com/bengali/news-50797621</td>\n",
       "      <td>রাশিয়ায় ক্ষমতার ২০ বছর যেভাবে কেটেছে ভ্লাদিম...</td>\n",
       "      <td>ভ্লাদিমির পুতিন তাঁর ক্ষমতায় থাকার ২০ বছর পূর...</td>\n",
       "      <td>গত ২০ বছরে তিনি রাশিয়ার প্রেসিডেন্ট এবং প্রধা...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news-46678346</td>\n",
       "      <td>https://www.bbc.com/bengali/news-46678346</td>\n",
       "      <td>সংসদ নির্বাচন: বরিশালে ছয়টি আসন কিন্তু সবার দ...</td>\n",
       "      <td>বাংলাদেশের দক্ষিণাঞ্চলীয় জেলা বরিশাল এখন তুমু...</td>\n",
       "      <td>বরিশাল সদরে চলছে নির্বাচনী প্রচার প্রচারণা। যদ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news-51860832</td>\n",
       "      <td>https://www.bbc.com/bengali/news-51860832</td>\n",
       "      <td>সর্বকালের সর্বশ্রেষ্ঠ বাঙালি: বিবিসি বাংলার জর...</td>\n",
       "      <td>দু'হাজার চার সালে বিবিসি বাংলা একটি 'শ্রোতা জর...</td>\n",
       "      <td>রবীন্দ্রনাথ ঠাকুর রবীন্দ্রনাথ ঠাকুর বাঙালির কা...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56310420</td>\n",
       "      <td>https://www.bbc.com/bengali/56310420</td>\n",
       "      <td>৭ই মার্চের ভাষণ: ৫০ বছর আগে রেসকোর্স ময়দানে উ...</td>\n",
       "      <td>'ভাষণ শুরু আগে মাথার উপর দিয়ে বিমান আর হেলিকপ...</td>\n",
       "      <td>আর কুমিল্লা থেকে বাস ভাড়া করে অনেকের সাথে নিজ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                        url  \\\n",
       "0  news-54690291  https://www.bbc.com/bengali/news-54690291   \n",
       "1  news-50797621  https://www.bbc.com/bengali/news-50797621   \n",
       "2  news-46678346  https://www.bbc.com/bengali/news-46678346   \n",
       "3  news-51860832  https://www.bbc.com/bengali/news-51860832   \n",
       "4       56310420       https://www.bbc.com/bengali/56310420   \n",
       "\n",
       "                                               title  \\\n",
       "0  দুর্গাপূজার সময়ে যেভাবে শোক পালন করেন 'মহিষাস...   \n",
       "1  রাশিয়ায় ক্ষমতার ২০ বছর যেভাবে কেটেছে ভ্লাদিম...   \n",
       "2  সংসদ নির্বাচন: বরিশালে ছয়টি আসন কিন্তু সবার দ...   \n",
       "3  সর্বকালের সর্বশ্রেষ্ঠ বাঙালি: বিবিসি বাংলার জর...   \n",
       "4  ৭ই মার্চের ভাষণ: ৫০ বছর আগে রেসকোর্স ময়দানে উ...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  হিন্দু বাঙালীরা যে সময়ে তাদের সবথেকে বড় উৎসব...   \n",
       "1  ভ্লাদিমির পুতিন তাঁর ক্ষমতায় থাকার ২০ বছর পূর...   \n",
       "2  বাংলাদেশের দক্ষিণাঞ্চলীয় জেলা বরিশাল এখন তুমু...   \n",
       "3  দু'হাজার চার সালে বিবিসি বাংলা একটি 'শ্রোতা জর...   \n",
       "4  'ভাষণ শুরু আগে মাথার উপর দিয়ে বিমান আর হেলিকপ...   \n",
       "\n",
       "                                                text  \n",
       "0  দুর্গাপুজায় মহিষাসুর বধ্যে মধ্য দিয়ে অশুভর ও...  \n",
       "1  গত ২০ বছরে তিনি রাশিয়ার প্রেসিডেন্ট এবং প্রধা...  \n",
       "2  বরিশাল সদরে চলছে নির্বাচনী প্রচার প্রচারণা। যদ...  \n",
       "3  রবীন্দ্রনাথ ঠাকুর রবীন্দ্রনাথ ঠাকুর বাঙালির কা...  \n",
       "4  আর কুমিল্লা থেকে বাস ভাড়া করে অনেকের সাথে নিজ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d70fa34",
   "metadata": {},
   "source": [
    "## csebuetnlp/\n",
    "#### banglat5_small\n",
    "#### banglabert_small \n",
    "#### banglabert_large\n",
    "#### banglabert\n",
    "\n",
    "## Dataset\n",
    "#### https://huggingface.co/datasets/csebuetnlp/xlsum\n",
    "#### https://huggingface.co/csebuetnlp/mT5_multilingual_XLSum\n",
    "#### https://huggingface.co/datasets/csebuetnlp/CrossSum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f666c39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80495d63830f4311838eb84bb90ab6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/376 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688c807c5a234f6282c4952d2b0913c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5e09cb90da4ecba234215ad00c27da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf287359f8f54820aa710ff936b5d15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# t5_tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\n",
    "t5_tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-base\")\n",
    "# t5_tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-large\")\n",
    "# t5_tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-xl\")\n",
    "# t5_tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-xxl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "963c7afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09865fb026a944fd95c76283e544c100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233f5cab11354b3a867b8290a44387d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8f4d047962444fb965e7f17b6096fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_sample_data(data):\n",
    "  # Max token size is 14536 and 215 for inputs and labels, respectively.\n",
    "  # Here I restrict these token size.\n",
    "  input_feature = t5_tokenizer(data[\"text\"], truncation=True, max_length=1024)\n",
    "  label = t5_tokenizer(data[\"summary\"], truncation=True, max_length=128)\n",
    "  return {\n",
    "    \"input_ids\": input_feature[\"input_ids\"],\n",
    "    \"attention_mask\": input_feature[\"attention_mask\"],\n",
    "    \"labels\": label[\"input_ids\"],\n",
    "  }\n",
    "\n",
    "tokenized_ds = ds.map(\n",
    "  tokenize_sample_data,\n",
    "  remove_columns=[\"id\", \"url\", \"title\", \"summary\", \"text\"],\n",
    "  batched=True,\n",
    "  batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43f749f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 8102\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1012\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1012\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76699b7a",
   "metadata": {},
   "source": [
    "### Before fine-tuning, load pre-trained model and data collator.\n",
    "\n",
    "### In HuggingFace, several sizes of mT5 models are available, and here I’ll use small one (google/mt5-small) to fit to memory in my machine.\n",
    "### The name is “small”, but it’s still so large (over 1 GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a218f20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99a5f61d2be4302b9ef32cea9a16a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda87622ddf74c69a70eec53021232d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoConfig, AutoModelForSeq2SeqLM\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# see https://huggingface.co/docs/transformers/main_classes/configuration\n",
    "mt5_config = AutoConfig.from_pretrained(\n",
    "#   \"google/mt5-small\",\n",
    "    \"google/mt5-base\",\n",
    "  max_length=128,\n",
    "  length_penalty=0.6,\n",
    "  no_repeat_ngram_size=2,\n",
    "  num_beams=15,\n",
    ")\n",
    "model = (AutoModelForSeq2SeqLM\n",
    "#          .from_pretrained(\"google/mt5-small\", config=mt5_config)\n",
    "         .from_pretrained(\"google/mt5-base\", config=mt5_config)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fbe55e",
   "metadata": {},
   "source": [
    "### For the sequence-to-sequence (seq2seq) task, we need to not only stack the inputs for encoder, but also prepare for the decoder side. In seq2seq setup, a common technique called “teach forcing” will then be applied in decoder.\n",
    "### In Hugging Face, these tasks are not needed to be manually setup and the following DataCollatorForSeq2Seq will take care of all steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77b7c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "  t5_tokenizer,\n",
    "  model=model,\n",
    "  return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132f6ab",
   "metadata": {},
   "source": [
    "### The idea of ROUGE is similar to BLEU, but it also measures how many of n-gram tokens in the reference text appears in the generated (predicted) text. (This is why the name of ROUGE includes “RO”, which means “Recall-Oriented”.)\n",
    "### There also exist variations, ROUGE-L and ROUGE-Lsum, which also counts the longest common substrings (LCS) in ROUGE metrics computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c09b4709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "# define function for custom tokenization\n",
    "def tokenize_sentence(arg):\n",
    "  encoded_arg = t5_tokenizer(arg)\n",
    "  return t5_tokenizer.convert_ids_to_tokens(encoded_arg.input_ids)\n",
    "\n",
    "# define function to get ROUGE scores with custom tokenization\n",
    "def metrics_func(eval_arg):\n",
    "  preds, labels = eval_arg\n",
    "  # Replace -100\n",
    "  labels = np.where(labels != -100, labels, t5_tokenizer.pad_token_id)\n",
    "  # Convert id tokens to text\n",
    "  text_preds = t5_tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "  text_labels = t5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "  # Insert a line break (\\n) in each sentence for ROUGE scoring\n",
    "  # (Note : Please change this code, when you perform on other languages except for Japanese)\n",
    "  text_preds = [(p if p.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else p + \"。\") for p in text_preds]\n",
    "  text_labels = [(l if l.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else l + \"。\") for l in text_labels]\n",
    "  sent_tokenizer_jp = RegexpTokenizer(u'[^!！?？。]*[!！?？。]')\n",
    "  text_preds = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(p))) for p in text_preds]\n",
    "  text_labels = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(l))) for l in text_labels]\n",
    "  # compute ROUGE score with custom tokenization\n",
    "  return rouge_metric.compute(\n",
    "    predictions=text_preds,\n",
    "    references=text_labels,\n",
    "    tokenizer=tokenize_sentence\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f010c7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.14564995526653984,\n",
       " 'rouge2': 0.06276546982429335,\n",
       " 'rougeL': 0.12597449887708753,\n",
       " 'rougeLsum': 0.12499410672022479}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sample_dataloader = DataLoader(\n",
    "  tokenized_ds[\"test\"].with_format(\"torch\"),\n",
    "  collate_fn=data_collator,\n",
    "  batch_size=5)\n",
    "for batch in sample_dataloader:\n",
    "  with torch.no_grad():\n",
    "    preds = model.generate(\n",
    "      batch[\"input_ids\"].to(device),\n",
    "      num_beams=15,\n",
    "      num_return_sequences=1,\n",
    "      no_repeat_ngram_size=1,\n",
    "      remove_invalid_values=True,\n",
    "      max_length=128,\n",
    "    )\n",
    "  labels = batch[\"labels\"]\n",
    "  break\n",
    "\n",
    "metrics_func([preds, labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5931eb4",
   "metadata": {},
   "source": [
    "### In usual training evaluation, training loss and accuracy will be computed and evaluated, by comparing the generated logits with labels. However, as we saw above, we want to evaluate ROUGE score using the predicted tokens.\n",
    "### To simplify these sequence-to-sequence specific steps, here I use built-in Seq2SeqTrainingArguments and Seq2SeqTrainer classes, instead of usual TrainingArguments and Trainer.\n",
    "### By setting predict_with_generate=True as follows in this class, the predicted tokens will be generated by model.generate() and it will then be passed into evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f034dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "  output_dir = \"mt5-summarize-Bengali\",\n",
    "  log_level = \"error\",\n",
    "  num_train_epochs = 10,\n",
    "  learning_rate = 5e-4,\n",
    "  lr_scheduler_type = \"linear\",\n",
    "  warmup_steps = 90,\n",
    "  optim = \"adafactor\",\n",
    "  weight_decay = 0.01,\n",
    "  per_device_train_batch_size = 2,\n",
    "  per_device_eval_batch_size = 1,\n",
    "  gradient_accumulation_steps = 16,\n",
    "  evaluation_strategy = \"steps\",\n",
    "  eval_steps = 100,\n",
    "  predict_with_generate=True,\n",
    "  generation_max_length = 128,\n",
    "  save_steps = 500,\n",
    "  logging_steps = 10,\n",
    "  push_to_hub = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03056f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "  model = model,\n",
    "  args = training_args,\n",
    "  data_collator = data_collator,\n",
    "  compute_metrics = metrics_func,\n",
    "  train_dataset = tokenized_ds[\"train\"],\n",
    "  eval_dataset = tokenized_ds[\"validation\"].select(range(20)),\n",
    "  tokenizer = t5_tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef0593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "# save fine-tuned model in local\n",
    "os.makedirs(\"./trained_for_summarization_jp\", exist_ok=True)\n",
    "if hasattr(trainer.model, \"module\"):\n",
    "  trainer.model.module.save_pretrained(\"./trained_for_summarization_jp\")\n",
    "else:\n",
    "  trainer.model.save_pretrained(\"./trained_for_summarization_jp\")\n",
    "\n",
    "# load local model\n",
    "model = (AutoModelForSeq2SeqLM\n",
    "         .from_pretrained(\"./trained_for_summarization_jp\")\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c5f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Predict with test data (first 5 rows)\n",
    "sample_dataloader = DataLoader(\n",
    "  tokenized_ds[\"test\"].with_format(\"torch\"),\n",
    "  collate_fn=data_collator,\n",
    "  batch_size=5)\n",
    "for batch in sample_dataloader:\n",
    "  with torch.no_grad():\n",
    "    preds = model.generate(\n",
    "      batch[\"input_ids\"].to(device),\n",
    "      num_beams=15,\n",
    "      num_return_sequences=1,\n",
    "      no_repeat_ngram_size=1,\n",
    "      remove_invalid_values=True,\n",
    "      max_length=128,\n",
    "    )\n",
    "  labels = batch[\"labels\"]\n",
    "  break\n",
    "\n",
    "# Replace -100 (see above)\n",
    "labels = np.where(labels != -100, labels, t5_tokenizer.pad_token_id)\n",
    "\n",
    "# Convert id tokens to text\n",
    "text_preds = t5_tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "text_labels = t5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "# Show result\n",
    "print(\"***** Input's Text *****\")\n",
    "print(ds[\"test\"][\"text\"][2])\n",
    "print(\"***** Summary Text (True Value) *****\")\n",
    "print(text_labels[2])\n",
    "print(\"***** Summary Text (Generated Text) *****\")\n",
    "print(text_preds[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c998828f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
