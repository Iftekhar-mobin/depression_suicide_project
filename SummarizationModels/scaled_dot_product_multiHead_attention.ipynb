{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e376ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import math, matmul, reshape, shape, transpose, cast, float32\n",
    "from tensorflow.keras.layers import Dense, Layer\n",
    "from keras.backend import softmax\n",
    "\n",
    "# Implementing the Scaled-Dot Product Attention\n",
    "class DotProductAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, queries, keys, values, d_k, mask=None):\n",
    "        # Scoring the queries against the keys after transposing the latter, and scaling\n",
    "        scores = matmul(queries, keys, transpose_b=True) / math.sqrt(cast(d_k, float32))\n",
    "\n",
    "        # Apply mask to the attention scores\n",
    "        if mask is not None:\n",
    "            scores += -1e9 * mask\n",
    "\n",
    "        # Computing the weights by a softmax operation\n",
    "        weights = softmax(scores)\n",
    "\n",
    "        # Computing the attention by a weighted sum of the value vectors\n",
    "        return matmul(weights, values)\n",
    "\n",
    "# Implementing the Multi-Head Attention\n",
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self, h, d_k, d_v, d_model, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.attention = DotProductAttention()  # Scaled dot product attention\n",
    "        self.heads = h  # Number of attention heads to use\n",
    "        self.d_k = d_k  # Dimensionality of the linearly projected queries and keys\n",
    "        self.d_v = d_v  # Dimensionality of the linearly projected values\n",
    "        self.d_model = d_model  # Dimensionality of the model\n",
    "        self.W_q = Dense(d_k)  # Learned projection matrix for the queries\n",
    "        self.W_k = Dense(d_k)  # Learned projection matrix for the keys\n",
    "        self.W_v = Dense(d_v)  # Learned projection matrix for the values\n",
    "        self.W_o = Dense(d_model)  # Learned projection matrix for the multi-head output\n",
    "\n",
    "    def reshape_tensor(self, x, heads, flag):\n",
    "        if flag:\n",
    "            # Tensor shape after reshaping and transposing: (batch_size, heads, seq_length, -1)\n",
    "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], heads, -1))\n",
    "            x = transpose(x, perm=(0, 2, 1, 3))\n",
    "        else:\n",
    "            # Reverting the reshaping and transposing operations: (batch_size, seq_length, d_k)\n",
    "            x = transpose(x, perm=(0, 2, 1, 3))\n",
    "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], self.d_k))\n",
    "        return x\n",
    "\n",
    "    def call(self, queries, keys, values, mask=None):\n",
    "        # Rearrange the queries to be able to compute all heads in parallel\n",
    "        q_reshaped = self.reshape_tensor(self.W_q(queries), self.heads, True)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "\n",
    "        # Rearrange the keys to be able to compute all heads in parallel\n",
    "        k_reshaped = self.reshape_tensor(self.W_k(keys), self.heads, True)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "\n",
    "        # Rearrange the values to be able to compute all heads in parallel\n",
    "        v_reshaped = self.reshape_tensor(self.W_v(values), self.heads, True)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "\n",
    "        # Compute the multi-head attention output using the reshaped queries, keys and values\n",
    "        o_reshaped = self.attention(q_reshaped, k_reshaped, v_reshaped, self.d_k, mask)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "\n",
    "        # Rearrange back the output into concatenated form\n",
    "        output = self.reshape_tensor(o_reshaped, self.heads, False)\n",
    "        # Resulting tensor shape: (batch_size, input_seq_length, d_v)\n",
    "\n",
    "        # Apply one final linear projection to the output to generate the multi-head attention\n",
    "        # Resulting tensor shape: (batch_size, input_seq_length, d_model)\n",
    "        return self.W_o(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e30c827d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.3180967   0.0787364  -0.26357287 ...  0.3872548   0.00483171\n",
      "    0.04735523]\n",
      "  [-0.31864977  0.08002001 -0.26464993 ...  0.3862469   0.00497038\n",
      "    0.0499613 ]\n",
      "  [-0.31949264  0.08121223 -0.2635065  ...  0.38711706  0.00367324\n",
      "    0.04288119]\n",
      "  [-0.31546456  0.08003737 -0.26213628 ...  0.3874932   0.00477415\n",
      "    0.04965784]\n",
      "  [-0.31746244  0.08079105 -0.2634564  ...  0.3869148   0.00575035\n",
      "    0.04653753]]\n",
      "\n",
      " [[-0.3633424  -0.02567701 -0.39059147 ...  0.4909815   0.08172845\n",
      "    0.06120498]\n",
      "  [-0.36070412 -0.02857012 -0.3880804  ...  0.4883473   0.08219243\n",
      "    0.06474067]\n",
      "  [-0.3640032  -0.02760756 -0.39163145 ...  0.49178454  0.081461\n",
      "    0.06035953]\n",
      "  [-0.36158007 -0.02802903 -0.38977474 ...  0.49198666  0.08570441\n",
      "    0.06211552]\n",
      "  [-0.3613088  -0.02842601 -0.38866863 ...  0.4894002   0.08181939\n",
      "    0.06449931]]\n",
      "\n",
      " [[-0.41653395  0.01244472 -0.30626333 ...  0.4565236   0.09132592\n",
      "   -0.01173389]\n",
      "  [-0.41902378  0.0105714  -0.30914053 ...  0.45580542  0.09197275\n",
      "   -0.01128043]\n",
      "  [-0.41768453  0.01056711 -0.3054197  ...  0.45584765  0.09097209\n",
      "   -0.00658924]\n",
      "  [-0.41763857  0.01001617 -0.30784157 ...  0.45488873  0.0925025\n",
      "   -0.00799472]\n",
      "  [-0.41730532  0.01315047 -0.3069562  ...  0.4545292   0.0928291\n",
      "   -0.00708573]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.27737287  0.0325871  -0.21674632 ...  0.40492943 -0.00648054\n",
      "   -0.07829225]\n",
      "  [-0.27757224  0.03475623 -0.21623434 ...  0.40453517 -0.00836614\n",
      "   -0.07548078]\n",
      "  [-0.27750635  0.03480343 -0.21312226 ...  0.40309936 -0.00768872\n",
      "   -0.07524731]\n",
      "  [-0.27618417  0.03364469 -0.21532331 ...  0.4040332  -0.00671265\n",
      "   -0.07597857]\n",
      "  [-0.27739203  0.033168   -0.21294157 ...  0.40298715 -0.00794219\n",
      "   -0.07509706]]\n",
      "\n",
      " [[-0.32253027  0.04384869 -0.4062178  ...  0.41899362  0.04534303\n",
      "   -0.06517235]\n",
      "  [-0.32294205  0.04607889 -0.4048182  ...  0.41844705  0.04449947\n",
      "   -0.0660473 ]\n",
      "  [-0.3254472   0.04488314 -0.4092431  ...  0.41653815  0.04222006\n",
      "   -0.06906077]\n",
      "  [-0.32496175  0.04295326 -0.4078034  ...  0.41800982  0.04388958\n",
      "   -0.065386  ]\n",
      "  [-0.32540777  0.04185604 -0.4070118  ...  0.4201164   0.04590422\n",
      "   -0.06487107]]\n",
      "\n",
      " [[-0.23824085  0.14587928 -0.24985975 ...  0.47193912  0.04415061\n",
      "   -0.02917983]\n",
      "  [-0.2422549   0.1430752  -0.24911273 ...  0.4723526   0.04290019\n",
      "   -0.02887586]\n",
      "  [-0.23848577  0.14803006 -0.24551181 ...  0.4756771   0.04273137\n",
      "   -0.02826084]\n",
      "  [-0.23773699  0.14653906 -0.24649462 ...  0.47247943  0.04314448\n",
      "   -0.03010176]\n",
      "  [-0.23829901  0.14674726 -0.24798219 ...  0.47521955  0.04165068\n",
      "   -0.02890953]]], shape=(64, 5, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_seq_length = 5  # Maximum length of the input sequence\n",
    "h = 8  # Number of self-attention heads\n",
    "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
    "d_v = 64  # Dimensionality of the linearly projected values\n",
    "d_model = 512  # Dimensionality of the model sub-layers' outputs\n",
    "batch_size = 64  # Batch size from the training process\n",
    " \n",
    "queries = random.random((batch_size, input_seq_length, d_k))\n",
    "keys = random.random((batch_size, input_seq_length, d_k))\n",
    "values = random.random((batch_size, input_seq_length, d_v))\n",
    " \n",
    "multihead_attention = MultiHeadAttention(h, d_k, d_v, d_model)\n",
    "print(multihead_attention(queries, keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dff4d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86c52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2fe3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0651460b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee388c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
